#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†æ‰€æœ‰å®¶åº­çš„å®Œæ•´è´¹ç”¨è®¡ç®—
æŒ‰Economy_7å’ŒEconomy_10åˆ†åˆ«å¤„ç†ï¼Œç»“æœä¿å­˜åˆ°./results/ç›®å½•
"""

import pandas as pd
import json
import os
import glob
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import logging
from cost_calculator import CompleteCostCalculator
from gurobi_optimizer import CorrectedOptimizationSystem

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BatchProcessor:
    def __init__(self, tariff_config_path: str):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            tariff_config_path: ç”µä»·é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.optimizer = CorrectedOptimizationSystem(tariff_config_path)
        self.calculator = CompleteCostCalculator(tariff_config_path)
        
        logger.info("æ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_all_houses(self, data_dir: str) -> Dict[str, List[str]]:
        """è·å–æ‰€æœ‰houseçš„åˆ—è¡¨"""
        houses = {"Economy_7": [], "Economy_10": []}
        
        for tariff_type in ["Economy_7", "Economy_10"]:
            tariff_dir = os.path.join(data_dir, tariff_type)
            if not os.path.exists(tariff_dir):
                continue
            
            house_dirs = glob.glob(os.path.join(tariff_dir, "house*"))
            for house_dir in house_dirs:
                house_id = os.path.basename(house_dir)
                csv_file = os.path.join(house_dir, f"tou_filtered_{house_id}_{tariff_type}.csv")
                
                if os.path.exists(csv_file):
                    houses[tariff_type].append(house_id)
        
        logger.info(f"æ‰¾åˆ°çš„houseæ•°é‡:")
        logger.info(f"  Economy_7: {len(houses['Economy_7'])} ä¸ª")
        logger.info(f"  Economy_10: {len(houses['Economy_10'])} ä¸ª")
        
        return houses
    
    def process_single_house(self, house_id: str, tariff_type: str, data_dir: str) -> Dict:
        """å¤„ç†å•ä¸ªhouse"""
        house_start_time = time.time()
        logger.info(f"å¼€å§‹å¤„ç†: {house_id} ({tariff_type})")

        try:
            # æ­¥éª¤1: è¿è¡ŒGurobiä¼˜åŒ–
            csv_file = os.path.join(data_dir, tariff_type, house_id, f"tou_filtered_{house_id}_{tariff_type}.csv")

            logger.info(f"  æ­¥éª¤1: Gurobiä¼˜åŒ–...")
            optimization_start_time = time.time()
            optimization_result = self.optimizer.optimize_single_file(csv_file, house_id, tariff_type)
            optimization_time = time.time() - optimization_start_time

            if optimization_result["status"] != "success":
                logger.error(f"  Gurobiä¼˜åŒ–å¤±è´¥: {optimization_result['status']}")
                return {"status": "optimization_failed", "house_id": house_id, "tariff_type": tariff_type}

            # æ­¥éª¤2: è®¡ç®—å®Œæ•´è´¹ç”¨
            logger.info(f"  æ­¥éª¤2: å®Œæ•´è´¹ç”¨è®¡ç®—...")
            cost_calculation_start_time = time.time()
            complete_result = self.calculator.calculate_complete_costs(house_id, tariff_type)
            cost_calculation_time = time.time() - cost_calculation_start_time

            if complete_result is None:
                logger.error(f"  å®Œæ•´è´¹ç”¨è®¡ç®—å¤±è´¥")
                return {"status": "cost_calculation_failed", "house_id": house_id, "tariff_type": tariff_type}

            # æ­¥éª¤3: ä¿å­˜åˆ°æŒ‡å®šç›®å½•
            logger.info(f"  æ­¥éª¤3: ä¿å­˜ç»“æœ...")
            save_start_time = time.time()
            self.save_to_results_directory(complete_result, house_id, tariff_type)
            save_time = time.time() - save_start_time

            # è®¡ç®—æ€»å¤„ç†æ—¶é—´
            total_processing_time = time.time() - house_start_time

            # æ—¶é—´ç»Ÿè®¡
            timing_stats = {
                "optimization_time_seconds": round(optimization_time, 2),
                "cost_calculation_time_seconds": round(cost_calculation_time, 2),
                "save_time_seconds": round(save_time, 2),
                "total_processing_time_seconds": round(total_processing_time, 2),
                "optimization_time_formatted": f"{optimization_time//60:.0f}m {optimization_time%60:.1f}s",
                "cost_calculation_time_formatted": f"{cost_calculation_time//60:.0f}m {cost_calculation_time%60:.1f}s",
                "save_time_formatted": f"{save_time//60:.0f}m {save_time%60:.1f}s",
                "total_processing_time_formatted": f"{total_processing_time//60:.0f}m {total_processing_time%60:.1f}s"
            }

            logger.info(f"  âœ… {house_id} å¤„ç†å®Œæˆ: æ€»èŠ‚çº¦ ${complete_result['total_savings']:.2f} ({complete_result['overall_savings_percentage']:.2f}%)")
            logger.info(f"  â±ï¸ æ—¶é—´ç»Ÿè®¡:")
            logger.info(f"     - ä¼˜åŒ–è°ƒåº¦: {timing_stats['optimization_time_formatted']}")
            logger.info(f"     - è´¹ç”¨è®¡ç®—: {timing_stats['cost_calculation_time_formatted']}")
            logger.info(f"     - ä¿å­˜ç»“æœ: {timing_stats['save_time_formatted']}")
            logger.info(f"     - æ€»è®¡æ—¶é—´: {timing_stats['total_processing_time_formatted']}")
            
            return {
                "status": "success",
                "house_id": house_id,
                "tariff_type": tariff_type,
                "total_events": complete_result['total_events'],
                "total_original_cost": complete_result['total_original_cost'],
                "total_optimized_cost": complete_result['total_optimized_cost'],
                "total_savings": complete_result['total_savings'],
                "overall_savings_percentage": complete_result['overall_savings_percentage'],
                "reschedulable_events": complete_result['reschedulable_events'],
                "optimized_events": complete_result['optimized_events'],
                "timing_stats": timing_stats
            }
            
        except Exception as e:
            logger.error(f"  å¤„ç† {house_id} æ—¶å‡ºé”™: {e}")
            return {"status": "error", "house_id": house_id, "tariff_type": tariff_type, "error": str(e)}
    
    def save_to_results_directory(self, complete_result: Dict, house_id: str, tariff_type: str):
        """ä¿å­˜ç»“æœåˆ°./results/ç›®å½•"""
        # åˆ›å»ºç»“æœç›®å½•
        results_dir = os.path.join("results", tariff_type, house_id)
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†çš„æ‰€æœ‰äº‹ä»¶è´¹ç”¨CSV
        csv_data = complete_result['all_event_costs']
        csv_df = pd.DataFrame(csv_data)
        csv_file = os.path.join(results_dir, f"complete_cost_analysis_{house_id}_{tariff_type}.csv")
        csv_df.to_csv(csv_file, index=False)
        
        # ä¿å­˜æ±‡æ€»ç»Ÿè®¡JSON
        summary = {k: v for k, v in complete_result.items() if k != 'all_event_costs'}
        summary['processing_timestamp'] = datetime.now().isoformat()
        
        json_file = os.path.join(results_dir, f"cost_summary_{house_id}_{tariff_type}.json")
        with open(json_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        logger.info(f"    ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
    
    def process_all_houses(self, data_dir: str):
        """å¤„ç†æ‰€æœ‰house"""
        batch_start_time = time.time()
        logger.info("å¼€å§‹æ‰¹é‡å¤„ç†æ‰€æœ‰house...")

        # è·å–æ‰€æœ‰houseåˆ—è¡¨
        all_houses = self.get_all_houses(data_dir)

        # å¤„ç†ç»“æœç»Ÿè®¡
        all_results = []
        tariff_timing = {}

        # å¤„ç†Economy_7
        logger.info(f"\nğŸ”µ å¼€å§‹å¤„ç† Economy_7 ({len(all_houses['Economy_7'])} ä¸ªhouse)")
        e7_start_time = time.time()
        for i, house_id in enumerate(all_houses['Economy_7']):
            logger.info(f"  è¿›åº¦: {i+1}/{len(all_houses['Economy_7'])}")
            result = self.process_single_house(house_id, "Economy_7", data_dir)
            all_results.append(result)
        e7_time = time.time() - e7_start_time
        tariff_timing["Economy_7"] = {
            "time_seconds": round(e7_time, 2),
            "time_formatted": f"{e7_time//3600:.0f}h {(e7_time%3600)//60:.0f}m {e7_time%60:.1f}s",
            "houses_count": len(all_houses["Economy_7"]),
            "avg_time_per_house": round(e7_time / len(all_houses["Economy_7"]), 2) if all_houses["Economy_7"] else 0
        }

        # å¤„ç†Economy_10
        logger.info(f"\nğŸŸ¢ å¼€å§‹å¤„ç† Economy_10 ({len(all_houses['Economy_10'])} ä¸ªhouse)")
        e10_start_time = time.time()
        for i, house_id in enumerate(all_houses['Economy_10']):
            logger.info(f"  è¿›åº¦: {i+1}/{len(all_houses['Economy_10'])}")
            result = self.process_single_house(house_id, "Economy_10", data_dir)
            all_results.append(result)
        e10_time = time.time() - e10_start_time
        tariff_timing["Economy_10"] = {
            "time_seconds": round(e10_time, 2),
            "time_formatted": f"{e10_time//3600:.0f}h {(e10_time%3600)//60:.0f}m {e10_time%60:.1f}s",
            "houses_count": len(all_houses["Economy_10"]),
            "avg_time_per_house": round(e10_time / len(all_houses["Economy_10"]), 2) if all_houses["Economy_10"] else 0
        }

        # è®¡ç®—æ€»æ—¶é—´
        total_batch_time = time.time() - batch_start_time

        # ä¿å­˜æ€»ä½“ç»Ÿè®¡
        self.save_overall_statistics(all_results, tariff_timing, total_batch_time)

        # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
        logger.info("\nâ±ï¸ æ‰¹é‡å¤„ç†æ—¶é—´ç»Ÿè®¡:")
        logger.info(f"  Economy_7: {tariff_timing['Economy_7']['time_formatted']} (å¹³å‡ {tariff_timing['Economy_7']['avg_time_per_house']:.1f}s/house)")
        logger.info(f"  Economy_10: {tariff_timing['Economy_10']['time_formatted']} (å¹³å‡ {tariff_timing['Economy_10']['avg_time_per_house']:.1f}s/house)")
        logger.info(f"  æ€»è®¡æ—¶é—´: {total_batch_time//3600:.0f}h {(total_batch_time%3600)//60:.0f}m {total_batch_time%60:.1f}s")

        logger.info("ğŸ‰ æ‰€æœ‰houseå¤„ç†å®Œæˆ!")
    
    def save_overall_statistics(self, all_results: List[Dict], tariff_timing: Dict, total_batch_time: float):
        """ä¿å­˜æ€»ä½“ç»Ÿè®¡"""
        logger.info("ä¿å­˜æ€»ä½“ç»Ÿè®¡...")

        # åˆ†ç±»ç»Ÿè®¡
        successful_results = [r for r in all_results if r["status"] == "success"]

        economy_7_results = [r for r in successful_results if r["tariff_type"] == "Economy_7"]
        economy_10_results = [r for r in successful_results if r["tariff_type"] == "Economy_10"]
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        def calculate_stats(results, tariff_name):
            if not results:
                return None
            
            return {
                "tariff_type": tariff_name,
                "total_houses": len(results),
                "total_events": sum(r["total_events"] for r in results),
                "total_reschedulable_events": sum(r["reschedulable_events"] for r in results),
                "total_optimized_events": sum(r["optimized_events"] for r in results),
                "total_original_cost": sum(r["total_original_cost"] for r in results),
                "total_optimized_cost": sum(r["total_optimized_cost"] for r in results),
                "total_savings": sum(r["total_savings"] for r in results),
                "average_savings_percentage": sum(r["overall_savings_percentage"] for r in results) / len(results),
                "min_savings_percentage": min(r["overall_savings_percentage"] for r in results),
                "max_savings_percentage": max(r["overall_savings_percentage"] for r in results)
            }
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        overall_stats = {
            "processing_timestamp": datetime.now().isoformat(),
            "total_houses_processed": len(all_results),
            "successful_houses": len(successful_results),
            "failed_houses": len(all_results) - len(successful_results),
            "economy_7_stats": calculate_stats(economy_7_results, "Economy_7"),
            "economy_10_stats": calculate_stats(economy_10_results, "Economy_10"),
            "timing_statistics": {
                "total_batch_time_seconds": round(total_batch_time, 2),
                "total_batch_time_formatted": f"{total_batch_time//3600:.0f}h {(total_batch_time%3600)//60:.0f}m {total_batch_time%60:.1f}s",
                "tariff_timing": tariff_timing
            },
            "detailed_results": all_results
        }
        
        # ä¿å­˜æ€»ä½“ç»Ÿè®¡
        os.makedirs("results", exist_ok=True)
        
        # JSONæ ¼å¼
        json_file = "results/overall_statistics.json"
        with open(json_file, 'w') as f:
            json.dump(overall_stats, f, indent=2)
        
        # CSVæ ¼å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
        csv_data = []
        for result in successful_results:
            row_data = {
                "House_ID": result["house_id"],
                "Tariff_Type": result["tariff_type"],
                "Total_Events": result["total_events"],
                "Reschedulable_Events": result["reschedulable_events"],
                "Optimized_Events": result["optimized_events"],
                "Original_Cost": result["total_original_cost"],
                "Optimized_Cost": result["total_optimized_cost"],
                "Total_Savings": result["total_savings"],
                "Savings_Percentage": result["overall_savings_percentage"]
            }

            # æ·»åŠ æ—¶é—´ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if "timing_stats" in result:
                timing = result["timing_stats"]
                row_data.update({
                    "Optimization_Time_Seconds": timing["optimization_time_seconds"],
                    "Cost_Calculation_Time_Seconds": timing["cost_calculation_time_seconds"],
                    "Total_Processing_Time_Seconds": timing["total_processing_time_seconds"]
                })

            csv_data.append(row_data)
        
        csv_df = pd.DataFrame(csv_data)
        csv_file = "results/overall_summary.csv"
        csv_df.to_csv(csv_file, index=False)
        
        logger.info(f"æ€»ä½“ç»Ÿè®¡å·²ä¿å­˜:")
        logger.info(f"  JSON: {json_file}")
        logger.info(f"  CSV: {csv_file}")
        
        # æ‰“å°æ±‡æ€»ä¿¡æ¯
        if overall_stats["economy_7_stats"]:
            e7_stats = overall_stats["economy_7_stats"]
            logger.info(f"\nğŸ“Š Economy_7 æ±‡æ€»:")
            logger.info(f"  å¤„ç†houseæ•°: {e7_stats['total_houses']}")
            logger.info(f"  æ€»äº‹ä»¶æ•°: {e7_stats['total_events']:,}")
            logger.info(f"  æ€»èŠ‚çº¦: ${e7_stats['total_savings']:.2f}")
            logger.info(f"  å¹³å‡èŠ‚çº¦ç‡: {e7_stats['average_savings_percentage']:.2f}%")
        
        if overall_stats["economy_10_stats"]:
            e10_stats = overall_stats["economy_10_stats"]
            logger.info(f"\nğŸ“Š Economy_10 æ±‡æ€»:")
            logger.info(f"  å¤„ç†houseæ•°: {e10_stats['total_houses']}")
            logger.info(f"  æ€»äº‹ä»¶æ•°: {e10_stats['total_events']:,}")
            logger.info(f"  æ€»èŠ‚çº¦: ${e10_stats['total_savings']:.2f}")
            logger.info(f"  å¹³å‡èŠ‚çº¦ç‡: {e10_stats['average_savings_percentage']:.2f}%")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ‰¹é‡å¤„ç†æ‰€æœ‰å®¶åº­çš„å®Œæ•´è´¹ç”¨è®¡ç®—")
    print("=" * 80)
    
    # é…ç½®è·¯å¾„
    base_dir = os.path.dirname(os.path.abspath(__file__))
    tariff_config = os.path.join(base_dir, "tariff_config.json")
    data_dir = os.path.join(os.path.dirname(base_dir), "flterted_data")
    
    # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨
    processor = BatchProcessor(tariff_config)
    
    # å¤„ç†æ‰€æœ‰house
    processor.process_all_houses(data_dir)
    
    print("\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
    print("ğŸ“ ç»“æœä¿å­˜åœ¨ ./results/ ç›®å½•ä¸‹")
    print("   - ./results/Economy_7/house*/")
    print("   - ./results/Economy_10/house*/")
    print("   - ./results/overall_statistics.json")
    print("   - ./results/overall_summary.csv")


if __name__ == "__main__":
    main()
