import pandas as pd
import os

# ğŸ¯ åŠŸç‡æµ‹é‡å™ªå£°é²æ£’æ€§å®éªŒè·¯å¾„é…ç½®
EXPERIMENT_DIR = "/home/deep/TimeSeries/Agent_V2/experiments/Robustness/01PowerMeasurementNoise"
OUTPUT_BASE_DIR = os.path.join(EXPERIMENT_DIR, "output")

# ========== Single household processing ==========
def add_event_id_single(
    house_id: str,
    input_csv: str,
    output_dir: str = None  # å°†ä½¿ç”¨å®éªŒè¾“å‡ºç›®å½•
) -> pd.DataFrame:
    """
    åŠŸç‡æµ‹é‡å™ªå£°å®éªŒ - ä¸ºå•ä¸ªæˆ¿å±‹æ·»åŠ äº‹ä»¶ID

    Args:
        house_id: House identifier (e.g., "house1")
        input_csv: Path to input event segments CSV
        output_dir: Output directory (will use experiment output if None)

    Returns:
        DataFrame with event IDs added
    """

    # ğŸ¯ ä½¿ç”¨åŠŸç‡æµ‹é‡å™ªå£°å®éªŒçš„è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = os.path.join(OUTPUT_BASE_DIR, "02_event_segments")

    print(f"ğŸ” åŠŸç‡æµ‹é‡å™ªå£°å®éªŒ - å¤„ç† {house_id.upper()} äº‹ä»¶IDåˆ†é…...")
    print("ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„ç”µå™¨æ“ä½œäº‹ä»¶åˆ†é…å”¯ä¸€æ ‡è¯†ç¬¦ 'event_id'...")

    if not os.path.isfile(input_csv):
        raise FileNotFoundError(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_csv}")

    # Create house-specific output directory
    house_output_dir = os.path.join(output_dir, house_id)
    os.makedirs(house_output_dir, exist_ok=True)

    output_csv = os.path.join(house_output_dir, f"02_appliance_event_segments_id_{house_id}.csv")

    df = pd.read_csv(input_csv, parse_dates=["start_time", "end_time"])

    # Add date column
    df["date"] = df["start_time"].dt.date.astype(str)

    # Generate cumulative index per (appliance_name, date) group
    df["event_index"] = df.groupby(["appliance_name", "date"]).cumcount() + 1

    # Generate event_id, e.g., Washer_2024-06-01_01
    df["event_id"] = (
        df["appliance_name"].str.replace(" ", "_") + "_" +
        df["date"] + "_" +
        df["event_index"].astype(str).str.zfill(2)
    )

    # Add reschedulable flag
    df["is_reschedulable"] = df["Shiftability"].apply(
        lambda x: True if x.strip().lower() == "shiftable" else False
    )

    # Reorder columns
    df = df[[
        "event_id", "appliance_name", "appliance_ID", "Shiftability",
        "start_time", "end_time", "duration(min)", "energy(W)", "is_reschedulable"
    ]]

    # Save result
    df.to_csv(output_csv, index=False)
    print(f"âœ… The event log with event_id for {house_id.upper()} has been saved to: {output_csv}")

    print(f"Note: Each event_id is a unique identifier that includes appliance name, date, and event index.")
    print(f"Here are the first 10 rows of the result for {house_id.upper()}:")
    print(df.head(10))

    return df


# ========== Batch processing ==========
def batch_add_event_id(
    house_data_dict: dict,
    input_dir: str = None,  # å°†ä½¿ç”¨å®éªŒè¾“å‡ºç›®å½•
    output_dir: str = None  # å°†ä½¿ç”¨å®éªŒè¾“å‡ºç›®å½•
) -> dict:
    """
    åŠŸç‡æµ‹é‡å™ªå£°å®éªŒ - æ‰¹é‡æ·»åŠ äº‹ä»¶ID

    Args:
        house_data_dict: Dictionary mapping house_id to house info
        input_dir: Directory containing event segments (will use experiment output if None)
        output_dir: Output directory (will use experiment output if None)

    Returns:
        Dictionary mapping house_id to result DataFrame
    """

    # ğŸ¯ ä½¿ç”¨åŠŸç‡æµ‹é‡å™ªå£°å®éªŒçš„è¾“å‡ºç›®å½•
    if input_dir is None:
        input_dir = os.path.join(OUTPUT_BASE_DIR, "02_event_segments")
    if output_dir is None:
        output_dir = os.path.join(OUTPUT_BASE_DIR, "02_event_segments")

    results = {}
    failed_houses = []

    print(f"ğŸš€ åŠŸç‡æµ‹é‡å™ªå£°å®éªŒ - æ‰¹é‡äº‹ä»¶IDåˆ†é…ï¼Œå¤„ç† {len(house_data_dict)} ä¸ªæˆ¿å±‹...")
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 80)

    for i, house_id in enumerate(house_data_dict.keys(), 1):
        try:
            print(f"\n[{i}/{len(house_data_dict)}] Processing {house_id}...")

            # Define input file path
            input_csv = os.path.join(input_dir, house_id, f"02_appliance_event_segments_{house_id}.csv")

            # Check if required file exists
            if not os.path.exists(input_csv):
                print(f"âŒ Event segments file not found: {input_csv}")
                failed_houses.append(house_id)
                continue

            # Add event IDs
            df_result = add_event_id_single(
                house_id=house_id,
                input_csv=input_csv,
                output_dir=output_dir
            )

            results[house_id] = df_result
            print(f"âœ… {house_id} completed successfully! Processed {len(df_result)} events")

        except Exception as e:
            print(f"âŒ Error processing {house_id}: {str(e)}")
            failed_houses.append(house_id)
            continue

        print("-" * 80)

    # Summary
    print(f"\nğŸ‰ Batch event ID assignment completed!")
    print(f"âœ… Successfully processed: {len(results)} households")
    if failed_houses:
        print(f"âŒ Failed to process: {len(failed_houses)} households")
        for failed_house in failed_houses:
            print(f"  - {failed_house}")

    # Display summary statistics
    total_events = sum(len(df) for df in results.values())
    print(f"ğŸ“Š Total events with IDs: {total_events}")

    return results


# ========== Legacy function for backward compatibility ==========
def add_event_id(
    input_csv: str = "./output/02_event_segments/02_appliance_event_segments.csv",
    output_csv: str = "./output/02_event_segments/02_appliance_event_segments_id.csv"
) -> pd.DataFrame:
    """Legacy function for backward compatibility"""
    print("Next, we will assign a unique identifier 'event_id' to each detected appliance operation event...")

    if not os.path.isfile(input_csv):
        raise FileNotFoundError(f"âŒ Input file not found: {input_csv}")

    df = pd.read_csv(input_csv, parse_dates=["start_time", "end_time"])

    # Add date column
    df["date"] = df["start_time"].dt.date.astype(str)

    # Generate cumulative index per (appliance_name, date) group
    df["event_index"] = df.groupby(["appliance_name", "date"]).cumcount() + 1

    # Generate event_id, e.g., Washer_2024-06-01_01
    df["event_id"] = (
        df["appliance_name"].str.replace(" ", "_") + "_" +
        df["date"] + "_" +
        df["event_index"].astype(str).str.zfill(2)
    )

    # Add reschedulable flag
    df["is_reschedulable"] = df["Shiftability"].apply(
        lambda x: True if x.strip().lower() == "shiftable" else False
    )

    # Reorder columns
    df = df[[
        "event_id", "appliance_name", "appliance_ID", "Shiftability",
        "start_time", "end_time", "duration(min)", "energy(W)", "is_reschedulable"
    ]]

    # Save result
    os.makedirs(os.path.dirname(output_csv), exist_ok=True)
    df.to_csv(output_csv, index=False)
    print(f"âœ… The event log with event_id has been saved to: {output_csv}")

    print("Note: Each event_id is a unique identifier that includes appliance name, date, and event index.")
    print("Here are the first 10 rows of the result:")
    print(df.head(10))

    return df










# # import pandas as pd
# # import os

# # def add_event_id(input_csv: str, output_csv: str) -> pd.DataFrame:
# #     if not os.path.isfile(input_csv):
# #         raise FileNotFoundError(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_csv}")

# #     df = pd.read_csv(input_csv, parse_dates=["start_time", "end_time"])

# #     # æ·»åŠ æ—¥æœŸå­—æ®µ
# #     df["date"] = df["start_time"].dt.date.astype(str)

# #     # ä¸ºæ¯ä¸ª appliance_name + date çš„ç»„åˆç”Ÿæˆç´¯åŠ ç´¢å¼•
# #     df["event_index"] = df.groupby(["appliance_name", "date"]).cumcount() + 1

# #     # ç”Ÿæˆ event_idï¼Œä¾‹å¦‚ï¼šWasher_2024-06-01_01
# #     df["event_id"] = (
# #         df["appliance_name"].str.replace(" ", "_") + "_" +
# #         df["date"] + "_" +
# #         df["event_index"].astype(str).str.zfill(2)
# #     )

# #     # æ·»åŠ æ˜¯å¦å¯è°ƒåº¦æ ‡å¿—
# #     df["is_reschedulable"] = df["Shiftability"].apply(
# #         lambda x: True if x.strip().lower() == "shiftable" else False
# #     )

# #     # é‡æ–°æ’åˆ—åˆ—é¡ºåº
# #     df = df[[
# #         "event_id", "appliance_name", "appliance_ID", "Shiftability",
# #         "start_time", "end_time", "duration(min)", "energy(W)", "is_reschedulable"
# #     ]]

# #     # ä¿å­˜ç»“æœ
# #     os.makedirs(os.path.dirname(output_csv), exist_ok=True)
# #     df.to_csv(output_csv, index=False)
# #     print(f"âœ… å« event_id çš„æ—¥å¿—è¡¨å·²ä¿å­˜è‡³ï¼š{output_csv}")
# #     return df


# import pandas as pd
# import os

# def add_event_id(
#     input_csv: str = "./output/02_event_segments/02_appliance_event_segments.csv",
#     output_csv: str = "./output/02_event_segments/02_appliance_event_segments_id.csv"
# ) -> pd.DataFrame:
#     print(" æ¥ä¸‹æ¥æˆ‘ä»¬å°†å¯¹æ‰€æœ‰è¯†åˆ«å‡ºçš„äº‹ä»¶æ·»åŠ ç‹¬ç‰¹çš„æ ‡è¯† event_id...")
#     if not os.path.isfile(input_csv):
#         raise FileNotFoundError(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_csv}")
    

#     df = pd.read_csv(input_csv, parse_dates=["start_time", "end_time"])

#     # æ·»åŠ æ—¥æœŸå­—æ®µ
#     df["date"] = df["start_time"].dt.date.astype(str)

#     # ä¸ºæ¯ä¸ª appliance_name + date çš„ç»„åˆç”Ÿæˆç´¯åŠ ç´¢å¼•
#     df["event_index"] = df.groupby(["appliance_name", "date"]).cumcount() + 1

#     # ç”Ÿæˆ event_idï¼Œä¾‹å¦‚ï¼šWasher_2024-06-01_01
#     df["event_id"] = (
#         df["appliance_name"].str.replace(" ", "_") + "_" +
#         df["date"] + "_" +
#         df["event_index"].astype(str).str.zfill(2)
#     )

#     # æ·»åŠ æ˜¯å¦å¯è°ƒåº¦æ ‡å¿—
#     df["is_reschedulable"] = df["Shiftability"].apply(
#         lambda x: True if x.strip().lower() == "shiftable" else False
#     )

#     # é‡æ–°æ’åˆ—åˆ—é¡ºåº
#     df = df[[ 
#         "event_id", "appliance_name", "appliance_ID", "Shiftability",
#         "start_time", "end_time", "duration(min)", "energy(W)", "is_reschedulable"
#     ]]

#     # ä¿å­˜ç»“æœ
#     os.makedirs(os.path.dirname(output_csv), exist_ok=True)
#     df.to_csv(output_csv, index=False)
#     print(f"âœ… å« event_id çš„æ—¥å¿—è¡¨å·²ä¿å­˜è‡³ï¼š{output_csv}")
    
#     print("è¯·æ³¨æ„ï¼ševent_id æ˜¯å”¯ä¸€çš„æ ‡è¯†ç¬¦ï¼ŒåŒ…å«äº†ç”µå™¨åç§°ã€æ—¥æœŸå’Œäº‹ä»¶ç´¢å¼•ã€‚")
#     print("æˆ‘å°†ä¸ºä½ å±•ç¤ºå‰10æ¡æ•°æ®ç»“æœã€‚")
#     print(df.head(10))  # æ˜¾ç¤ºå‰5è¡Œæ•°æ®ä»¥éªŒè¯ç»“æœ

#     return df










