import os
import pandas as pd
from typing import Tuple

# ğŸ¯ åŠŸç‡æµ‹é‡å™ªå£°é²æ£’æ€§å®éªŒè·¯å¾„é…ç½®
EXPERIMENT_DIR = "/home/deep/TimeSeries/Agent_V2/experiments/Robustness/01PowerMeasurementNoise"
NOISE_DATA_DIR = os.path.join(EXPERIMENT_DIR, "Noise_data")
OUTPUT_BASE_DIR = os.path.join(EXPERIMENT_DIR, "output")

# ========== Parameter Settings ==========
# ğŸ¯ è°ƒæ•´å‚æ•°ä»¥å‡å°‘è¿‡å¤šçš„çŸ­æ—¶é—´äº‹ä»¶
DEFAULT_PMIN = 10.0  # æé«˜æœ€å°åŠŸç‡é˜ˆå€¼åˆ°10Wï¼Œè¿‡æ»¤æ‰å¾…æœºåŠŸç‡
DEFAULT_TMIN = 5     # æé«˜æœ€å°æŒç»­æ—¶é—´åˆ°5åˆ†é’Ÿï¼Œè¿‡æ»¤æ‰ç¬æ—¶æ³¢åŠ¨
BASELOAD_PMIN = 5.0  # åŸºç¡€è´Ÿè½½æœ€å°åŠŸç‡é˜ˆå€¼
BASELOAD_TMIN = 10   # åŸºç¡€è´Ÿè½½æœ€å°æŒç»­æ—¶é—´

# ========== Utility Function: Load Data ==========
def load_power_data(power_csv: str) -> pd.DataFrame:
    if not os.path.isfile(power_csv):
        raise ValueError(f"âŒ The input path {power_csv} is not a valid file. Please check the path.")
    df = pd.read_csv(power_csv, parse_dates=["Time"])
    df.set_index("Time", inplace=True)
    return df

def load_appliance_thresholds(label_csv: str) -> dict:
    df = pd.read_csv(label_csv)
    thresholds = {}
    for _, row in df.iterrows():
        aid = row["ApplianceID"]
        name = row["ApplianceName"]
        shift = row["Shiftability"]
        pmin = row.get("Pmin", DEFAULT_PMIN)
        tmin = row.get("Tmin", DEFAULT_TMIN)
        thresholds[aid] = {
            "ApplianceName": name,
            "Shiftability": shift,
            "Pmin": float(pmin) if not pd.isna(pmin) else DEFAULT_PMIN,
            "Tmin": int(tmin) if not pd.isna(tmin) else DEFAULT_TMIN
        }
    return thresholds

# ========== Event Segmentation Strategies ==========
def segment_events_general(series: pd.Series, pmin: float, tmin: int) -> list:
    segments = []
    active = series > pmin
    current_start = None

    for i in range(len(series)):
        time = series.index[i]
        if active.iloc[i]:
            if current_start is None:
                current_start = time
        else:
            if current_start is not None:
                duration = (time - current_start).total_seconds() / 60
                if duration >= tmin:
                    segment = series[current_start:time]
                    energy = segment.sum()
                    segments.append((current_start, time, duration, energy))
                current_start = None

    if current_start is not None:
        duration = (series.index[-1] - current_start).total_seconds() / 60
        if duration >= tmin:
            segment = series[current_start:]
            energy = segment.sum()
            segments.append((current_start, series.index[-1], duration, energy))

    return segments

def segment_events_for_baseload(series: pd.Series, pmin: float, tmin: int) -> list:
    return segment_events_general(series, pmin=BASELOAD_PMIN, tmin=BASELOAD_TMIN)

def segment_events_for_shiftable(series: pd.Series, pmin: float, tmin: int) -> list:
    return segment_events_general(series, pmin, tmin)

def segment_events_for_non_shiftable(series: pd.Series, pmin: float, tmin: int) -> list:
    return segment_events_general(series, pmin, tmin)

# ========== Main Process ==========
def process_all_appliances(power_csv: str, label_csv: str, output_csv: str) -> pd.DataFrame:
    print("Now we will detect operation events for all appliances. Continuous power usage data will be segmented into discrete operation events...")
    df_power = load_power_data(power_csv)
    thresholds = load_appliance_thresholds(label_csv)

    all_segments = []

    for aid, params in thresholds.items():
        if aid not in df_power.columns:
            print(f"âš ï¸ Appliance column missing in data: {aid}. Skipping.")
            continue

        series = df_power[aid]
        shift = params["Shiftability"]
        name = params["ApplianceName"]
        pmin = params["Pmin"]
        tmin = params["Tmin"]

        if shift == "Base":
            segs = segment_events_for_baseload(series, pmin, tmin)
        elif shift == "Shiftable":
            segs = segment_events_for_shiftable(series, pmin, tmin)
        else:
            segs = segment_events_for_non_shiftable(series, pmin, tmin)

        for (start, end, dur, energy) in segs:
            all_segments.append({
                "appliance_ID": aid,
                "appliance_name": name,
                "Shiftability": shift,
                "start_time": start,
                "end_time": end,
                "duration(min)": round(dur, 2),
                "energy(W)": round(energy, 2)
            })

    result_df = pd.DataFrame(all_segments)
    os.makedirs(os.path.dirname(output_csv), exist_ok=True)
    result_df.to_csv(output_csv, index=False)
    print(f"âœ… Appliance operation event detection completed. Result saved to: {output_csv}")
    print(f"âœ… Total number of detected events: {len(result_df)}")
    print("âœ… Here are the first 10 records from the result:")
    print(result_df.head(10))
    return result_df

# ========== Enhanced API for single household ==========
def run_event_segmentation_single(
    house_id: str,
    power_csv: str,
    label_csv: str,
    output_dir: str = "./output/02_event_segments/"
) -> pd.DataFrame:
    """
    Run event segmentation for a single household

    Args:
        house_id: House identifier (e.g., "house1")
        power_csv: Path to power data CSV
        label_csv: Path to appliance label CSV
        output_dir: Output directory

    Returns:
        DataFrame with segmented events
    """
    # Create house-specific output directory
    house_output_dir = os.path.join(output_dir, house_id)
    os.makedirs(house_output_dir, exist_ok=True)

    output_csv = os.path.join(house_output_dir, f"02_appliance_event_segments_{house_id}.csv")

    print(f"ğŸ” Processing {house_id.upper()} event segmentation...")

    return process_all_appliances(power_csv, label_csv, output_csv)


# ========== Batch processing API ==========
def batch_run_event_segmentation(
    house_data_dict: dict,
    input_dir: str = None,  # å°†ä½¿ç”¨å™ªå£°æ•°æ®ç›®å½•
    label_dir: str = None,  # å°†ä½¿ç”¨å®éªŒè¾“å‡ºç›®å½•
    output_dir: str = None  # å°†ä½¿ç”¨å®éªŒè¾“å‡ºç›®å½•
) -> dict:
    """
    åŠŸç‡æµ‹é‡å™ªå£°é²æ£’æ€§å®éªŒ - æ‰¹é‡äº‹ä»¶åˆ†å‰²

    Args:
        house_data_dict: Dictionary mapping house_id to house info
        input_dir: Directory containing noisy power data (will use NOISE_DATA_DIR if None)
        label_dir: Directory containing appliance labels (will use experiment output if None)
        output_dir: Directory to save event segments (will use experiment output if None)

    Returns:
        Dictionary mapping house_id to result DataFrame
    """

    # ğŸ¯ ä½¿ç”¨åŠŸç‡æµ‹é‡å™ªå£°å®éªŒçš„è·¯å¾„é…ç½®
    if input_dir is None:
        input_dir = NOISE_DATA_DIR
    if label_dir is None:
        label_dir = os.path.join(OUTPUT_BASE_DIR, "02_behavior_modeling")
    if output_dir is None:
        output_dir = os.path.join(OUTPUT_BASE_DIR, "02_event_segments")

    results = {}
    failed_houses = []

    print(f"ğŸš€ åŠŸç‡æµ‹é‡å™ªå£°å®éªŒ - æ‰¹é‡äº‹ä»¶åˆ†å‰²ï¼Œå¤„ç† {len(house_data_dict)} ä¸ªæˆ¿å±‹...")
    print(f"ğŸ“ å™ªå£°æ•°æ®ç›®å½•: {input_dir}")
    print(f"ğŸ“ æ ‡ç­¾ç›®å½•: {label_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 80)

    for i, house_id in enumerate(house_data_dict.keys(), 1):
        try:
            print(f"\n[{i}/{len(house_data_dict)}] Processing {house_id}...")

            # ğŸ¯ å®šä¹‰æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨å™ªå£°æ•°æ®
            power_csv = os.path.join(input_dir, house_id, f"01_perception_alignment_result_{house_id}_noisy.csv")
            label_csv = os.path.join(label_dir, house_id, f"02_1_appliance_shiftable_label_{house_id}.csv")  # æ¯ä¸ªæˆ¿å±‹æœ‰è‡ªå·±çš„æ ‡ç­¾æ–‡ä»¶

            # Check if required files exist
            if not os.path.exists(power_csv):
                print(f"âŒ Power data file not found: {power_csv}")
                failed_houses.append(house_id)
                continue

            if not os.path.exists(label_csv):
                print(f"âŒ Label file not found: {label_csv}")
                failed_houses.append(house_id)
                continue

            # Run event segmentation
            df_result = run_event_segmentation_single(
                house_id=house_id,
                power_csv=power_csv,
                label_csv=label_csv,
                output_dir=output_dir
            )

            results[house_id] = df_result
            print(f"âœ… {house_id} completed successfully! Generated {len(df_result)} events")

        except Exception as e:
            print(f"âŒ Error processing {house_id}: {str(e)}")
            failed_houses.append(house_id)
            continue

        print("-" * 80)

    # Summary
    print(f"\nğŸ‰ Batch event segmentation completed!")
    print(f"âœ… Successfully processed: {len(results)} households")
    if failed_houses:
        print(f"âŒ Failed to process: {len(failed_houses)} households")
        for failed_house in failed_houses:
            print(f"  - {failed_house}")

    # Display summary statistics
    total_events = sum(len(df) for df in results.values())
    print(f"ğŸ“Š Total events generated: {total_events}")

    return results


# ========== Legacy API for backward compatibility ==========
def run_event_segmentation(
    power_csv=None,  # å°†ä½¿ç”¨å™ªå£°æ•°æ®
    label_csv=None,  # å°†ä½¿ç”¨å®éªŒè¾“å‡º
    output_csv=None  # å°†ä½¿ç”¨å®éªŒè¾“å‡º
):
    """åŠŸç‡æµ‹é‡å™ªå£°å®éªŒç‰ˆæœ¬ - Legacy function for backward compatibility"""

    # ğŸ¯ ä½¿ç”¨åŠŸç‡æµ‹é‡å™ªå£°å®éªŒçš„é»˜è®¤è·¯å¾„
    if power_csv is None:
        power_csv = os.path.join(NOISE_DATA_DIR, "house1/01_perception_alignment_result_house1_noisy.csv")
    if label_csv is None:
        label_csv = os.path.join(OUTPUT_BASE_DIR, "02_behavior_modeling/02_1_appliance_shiftable_label.csv")
    if output_csv is None:
        output_csv = os.path.join(OUTPUT_BASE_DIR, "02_event_segments/02_appliance_event_segments.csv")

    return process_all_appliances(power_csv, label_csv, output_csv)




















# import os
# import pandas as pd
# from typing import Tuple

# # ========== å‚æ•°è®¾ç½® ==========
# DEFAULT_PMIN = 2.0
# DEFAULT_TMIN = 1  # minutes
# BASELOAD_PMIN = 1.0
# BASELOAD_TMIN = 5

# # ========== å·¥å…·å‡½æ•°ï¼šè¯»å–æ•°æ® ==========
# def load_power_data(power_csv: str) -> pd.DataFrame:
#     if not os.path.isfile(power_csv):
#         raise ValueError(f"âŒ è¾“å…¥è·¯å¾„ {power_csv} ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
#     df = pd.read_csv(power_csv, parse_dates=["Time"])
#     df.set_index("Time", inplace=True)
#     return df

# def load_appliance_thresholds(label_csv: str) -> dict:
#     df = pd.read_csv(label_csv)
#     thresholds = {}
#     for _, row in df.iterrows():
#         aid = row["ApplianceID"]
#         name = row["ApplianceName"]
#         shift = row["Shiftability"]
#         pmin = row.get("Pmin", DEFAULT_PMIN)
#         tmin = row.get("Tmin", DEFAULT_TMIN)
#         thresholds[aid] = {
#             "ApplianceName": name,
#             "Shiftability": shift,
#             "Pmin": float(pmin) if not pd.isna(pmin) else DEFAULT_PMIN,
#             "Tmin": int(tmin) if not pd.isna(tmin) else DEFAULT_TMIN
#         }
#     return thresholds

# # ========== ä¸åŒç”µå™¨ç­–ç•¥çš„åˆ†æ®µå‡½æ•° ==========
# def segment_events_general(series: pd.Series, pmin: float, tmin: int) -> list:
#     segments = []
#     active = series > pmin
#     current_start = None

#     for i in range(len(series)):
#         time = series.index[i]
#         if active.iloc[i]:
#             if current_start is None:
#                 current_start = time
#         else:
#             if current_start is not None:
#                 duration = (time - current_start).total_seconds() / 60
#                 if duration >= tmin:
#                     segment = series[current_start:time]
#                     energy = segment.sum()
#                     segments.append((current_start, time, duration, energy))
#                 current_start = None

#     if current_start is not None:
#         duration = (series.index[-1] - current_start).total_seconds() / 60
#         if duration >= tmin:
#             segment = series[current_start:]
#             energy = segment.sum()
#             segments.append((current_start, series.index[-1], duration, energy))

#     return segments

# def segment_events_for_baseload(series: pd.Series, pmin: float, tmin: int) -> list:
#     return segment_events_general(series, pmin=BASELOAD_PMIN, tmin=BASELOAD_TMIN)

# def segment_events_for_shiftable(series: pd.Series, pmin: float, tmin: int) -> list:
#     return segment_events_general(series, pmin, tmin)

# def segment_events_for_non_shiftable(series: pd.Series, pmin: float, tmin: int) -> list:
#     return segment_events_general(series, pmin, tmin)

# # ========== ä¸»æµç¨‹ ==========
# def process_all_appliances(power_csv: str, label_csv: str, output_csv: str) -> pd.DataFrame:
#     print("æ¥ä¸‹æ¥æˆ‘ä»¬å°†å¯¹æ‰€æœ‰ç”µå™¨çš„æ—¶åºæ•°æ®è¿›è¡Œäº‹ä»¶è¯†åˆ«å¤„ç†ï¼Œæ‰€æœ‰è¿ç»­çš„è¿è¡Œæ•°æ®è¢«å¤„ç†æˆç¦»æ•£çš„å·¥ä½œäº‹ä»¶...")
#     df_power = load_power_data(power_csv)
#     thresholds = load_appliance_thresholds(label_csv)

#     all_segments = []

#     for aid, params in thresholds.items():
#         if aid not in df_power.columns:
#             print(f"âš ï¸ æ•°æ®ä¸­ç¼ºå¤±ç”µå™¨åˆ—ï¼š{aid}ï¼Œå·²è·³è¿‡ã€‚")
#             continue

#         series = df_power[aid]
#         shift = params["Shiftability"]
#         name = params["ApplianceName"]
#         pmin = params["Pmin"]
#         tmin = params["Tmin"]

#         if shift == "Base":
#             segs = segment_events_for_baseload(series, pmin, tmin)
#         elif shift == "Shiftable":
#             segs = segment_events_for_shiftable(series, pmin, tmin)
#         else:
#             segs = segment_events_for_non_shiftable(series, pmin, tmin)

#         for (start, end, dur, energy) in segs:
#             all_segments.append({
#                 "appliance_ID": aid,
#                 "appliance_name": name,
#                 "Shiftability": shift,
#                 "start_time": start,
#                 "end_time": end,
#                 "duration(min)": round(dur, 2),
#                 "energy(W)": round(energy, 2)
#             })

#     result_df = pd.DataFrame(all_segments)
#     os.makedirs(os.path.dirname(output_csv), exist_ok=True)
#     result_df.to_csv(output_csv, index=False)
#     print(f"âœ… å„ä¸ªç”µå™¨çš„è¿è¡Œäº‹ä»¶ç»“æœå·²ç»å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š{output_csv}")
#     print(f"âœ… å¤„ç†ç»“æœåŒ…å« {len(result_df)} æ¡äº‹ä»¶è®°å½•ã€‚")
#     print("âœ… å¤„ç†ç»“æœçš„å‰10æ¡è®°å½•å¦‚ä¸‹ï¼š")
#     print(result_df.head(10))
#     return result_df

# # ========== å¯¹å¤–è°ƒç”¨å…¥å£ ==========
# def run_event_segmentation(
#     power_csv="./output/01_preprocessed/01_perception_alignment_result.csv",
#     label_csv="./output/02_behavior_modeling/02_1_appliance_shiftable_label.csv",
#     output_csv="./output/02_event_segments/02_appliance_event_segments.csv"
# ):    
#     return process_all_appliances(power_csv, label_csv, output_csv)


