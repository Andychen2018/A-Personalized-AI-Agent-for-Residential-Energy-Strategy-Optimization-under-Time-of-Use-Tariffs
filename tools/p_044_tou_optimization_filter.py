

import os
import json
import pandas as pd
from datetime import datetime

def time_to_minutes(time_str):
    """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†é’Ÿæ•°"""
    h, m = map(int, time_str.split(":"))
    return h * 60 + m

def get_price_levels(tariff_config, tariff_name):
    """è·å–ç”µä»·ç­‰çº§ä¿¡æ¯ï¼Œè¿”å›æŒ‰ä»·æ ¼æ’åºçš„ç­‰çº§"""
    config_key = list(tariff_config.keys())[0] if len(tariff_config) == 1 else tariff_name
    tariff_plan = tariff_config[config_key]

    if tariff_plan.get("type") == "flat":
        return {"levels": [], "time_blocks": []}

    # è·å–æ—¶é—´å—
    time_blocks = []
    if "time_blocks" in tariff_plan:
        time_blocks = tariff_plan["time_blocks"]
    elif "seasonal_rates" in tariff_plan:
        time_blocks = tariff_plan["seasonal_rates"]["summer"]["time_blocks"]
    elif "periods" in tariff_plan:
        time_blocks = [{"start": p["start"], "end": p["end"], "rate": p["rate"]}
                      for p in tariff_plan["periods"]]

    # æŒ‰ä»·æ ¼æ’åºï¼Œè·å–ä»·æ ¼ç­‰çº§
    unique_rates = sorted(set(block["rate"] for block in time_blocks))
    rate_to_level = {rate: idx for idx, rate in enumerate(unique_rates)}

    # ä¸ºæ¯ä¸ªæ—¶é—´å—æ·»åŠ ç­‰çº§ä¿¡æ¯
    for block in time_blocks:
        block["price_level"] = rate_to_level[block["rate"]]

    return {
        "levels": unique_rates,  # [0.15, 0.25, 0.35, 0.45]
        "time_blocks": time_blocks,
        "min_level": 0,  # æœ€ä½ä»·æ ¼ç­‰çº§
        "max_level": len(unique_rates) - 1  # æœ€é«˜ä»·æ ¼ç­‰çº§
    }

def get_seasonal_price_levels(tariff_config, tariff_name, month):
    """è·å–ç‰¹å®šæœˆä»½çš„å­£èŠ‚æ€§ç”µä»·ç­‰çº§ä¿¡æ¯"""
    config_key = list(tariff_config.keys())[0] if len(tariff_config) == 1 else tariff_name
    tariff_plan = tariff_config[config_key]

    if "seasonal_rates" not in tariff_plan:
        return get_price_levels(tariff_config, tariff_name)

    # ç¡®å®šæœˆä»½å±äºå“ªä¸ªå­£èŠ‚
    time_blocks = []
    for season_name, season_data in tariff_plan["seasonal_rates"].items():
        if month in season_data["months"]:
            time_blocks = season_data["time_blocks"]
            break

    if not time_blocks:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”å­£èŠ‚ï¼Œä½¿ç”¨å¤å­£ä½œä¸ºé»˜è®¤
        time_blocks = tariff_plan["seasonal_rates"]["summer"]["time_blocks"]

    # æŒ‰ä»·æ ¼æ’åºï¼Œè·å–ä»·æ ¼ç­‰çº§
    unique_rates = sorted(set(block["rate"] for block in time_blocks))
    rate_to_level = {rate: idx for idx, rate in enumerate(unique_rates)}

    # ä¸ºæ¯ä¸ªæ—¶é—´å—æ·»åŠ ç­‰çº§ä¿¡æ¯
    for block in time_blocks:
        block["price_level"] = rate_to_level[block["rate"]]

    return {
        "levels": unique_rates,
        "time_blocks": time_blocks,
        "min_level": 0,
        "max_level": len(unique_rates) - 1
    }

def get_event_price_profile(start_time, end_time, price_info):
    """åˆ†æäº‹ä»¶åœ¨å„ä»·æ ¼ç­‰çº§çš„æ—¶é—´åˆ†å¸ƒ"""
    if not price_info["time_blocks"]:
        return {}
        
    event_start_min = start_time.hour * 60 + start_time.minute
    event_end_min = end_time.hour * 60 + end_time.minute
    
    # ç¡®ä¿äº‹ä»¶åœ¨åŒä¸€å¤©å†…ï¼ˆä¸å¤„ç†è·¨å¤©äº‹ä»¶ï¼‰
    if event_end_min < event_start_min:
        event_end_min += 1440  # åŠ ä¸€å¤©çš„åˆ†é’Ÿæ•°
    
    level_minutes = {}
    
    for block in price_info["time_blocks"]:
        block_start = time_to_minutes(block["start"])
        block_end = time_to_minutes(block["end"])
        level = block["price_level"]
        
        # å¤„ç†è·¨å¤©çš„æ—¶é—´å—ï¼ˆå¦‚Economy_7: 00:30-07:30å®é™…æ˜¯å‰ä¸€å¤©23:30-07:30ï¼‰
        if block_end <= block_start:
            # è·¨å¤©æ—¶é—´å—ï¼Œåˆ†æˆä¸¤æ®µå¤„ç†
            # ç¬¬ä¸€æ®µï¼šblock_start åˆ° 1440 (24:00)
            overlap_start_1 = max(event_start_min, block_start)
            overlap_end_1 = min(event_end_min, 1440)
            if overlap_start_1 < overlap_end_1:
                overlap_minutes_1 = overlap_end_1 - overlap_start_1
                level_minutes[level] = level_minutes.get(level, 0) + overlap_minutes_1
            
            # ç¬¬äºŒæ®µï¼š0 (00:00) åˆ° block_end
            overlap_start_2 = max(event_start_min, 0)
            overlap_end_2 = min(event_end_min, block_end)
            if overlap_start_2 < overlap_end_2:
                overlap_minutes_2 = overlap_end_2 - overlap_start_2
                level_minutes[level] = level_minutes.get(level, 0) + overlap_minutes_2
        else:
            # æ­£å¸¸æ—¶é—´å—
            overlap_start = max(event_start_min, block_start)
            overlap_end = min(event_end_min, block_end)
            
            if overlap_start < overlap_end:
                overlap_minutes = overlap_end - overlap_start
                level_minutes[level] = level_minutes.get(level, 0) + overlap_minutes
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é‡å ï¼Œä½¿ç”¨fallbackæœºåˆ¶
    if not level_minutes:
        # å°è¯•ä½¿ç”¨äº‹ä»¶å¼€å§‹æ—¶é—´çš„ä»·æ ¼ç­‰çº§
        fallback_level = get_time_price_level(start_time, price_info)
        if fallback_level >= 0:
            event_duration = event_end_min - event_start_min
            if event_duration > 1440:  # é˜²æ­¢è·¨å¤©è®¡ç®—é”™è¯¯
                event_duration = int((end_time - start_time).total_seconds() / 60)
            level_minutes[fallback_level] = event_duration
        else:
            # æœ€åçš„fallbackï¼šä½¿ç”¨æœ€ä½ä»·æ ¼ç­‰çº§
            event_duration = int((end_time - start_time).total_seconds() / 60)
            level_minutes[price_info["min_level"]] = event_duration
    
    # Ensure all price levels are represented in the result, even if 0 minutes
    complete_level_minutes = {}
    for level in range(price_info["min_level"], price_info["max_level"] + 1):
        complete_level_minutes[level] = level_minutes.get(level, 0)

    return complete_level_minutes

def get_time_price_level(timestamp, price_info):
    """è·å–æŒ‡å®šæ—¶é—´ç‚¹çš„ä»·æ ¼ç­‰çº§"""
    if not price_info["time_blocks"]:
        return price_info.get("min_level", 0)
        
    time_minutes = timestamp.hour * 60 + timestamp.minute
    
    for block in price_info["time_blocks"]:
        block_start = time_to_minutes(block["start"])
        block_end = time_to_minutes(block["end"])
        
        # å¤„ç†è·¨å¤©çš„æ—¶é—´å—
        if block_end <= block_start:
            # è·¨å¤©æƒ…å†µï¼šæ£€æŸ¥æ˜¯å¦åœ¨ååŠæ®µ(00:00-block_end)æˆ–å‰åŠæ®µ(block_start-1440)
            if time_minutes < block_end or time_minutes >= block_start:
                return block["price_level"]
        else:
            # æ­£å¸¸æƒ…å†µ
            if block_start <= time_minutes < block_end:
                return block["price_level"]
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ—¶é—´å—ï¼Œè¿”å›æœ€ä½ä»·æ ¼ç­‰çº§
    return price_info.get("min_level", 0)

def should_keep_for_rescheduling(level_minutes, price_info, threshold_minutes=5):
    """åˆ¤æ–­äº‹ä»¶æ˜¯å¦å€¼å¾—è°ƒåº¦ä¼˜åŒ– - ä¿®æ­£åçš„é€»è¾‘"""
    if not level_minutes:
        return False

    # ä¿®æ­£åçš„TOUè¿‡æ»¤é€»è¾‘ï¼š
    # 1. è®¡ç®—äº‹ä»¶åœ¨å„ä¸ªéæœ€ä½ä»·æ ¼ç­‰çº§çš„æ€»æŒç»­æ—¶é—´
    high_price_total_minutes = sum(minutes for level, minutes in level_minutes.items()
                                  if level > price_info["min_level"])

    # 2. å¦‚æœäº‹ä»¶åœ¨é«˜ä»·æ ¼åŒºé—´çš„æŒç»­æ—¶é—´ >= é˜ˆå€¼ï¼Œå€¼å¾—è°ƒåº¦
    if high_price_total_minutes >= threshold_minutes:
        return True

    # 3. å¦‚æœäº‹ä»¶å®Œå…¨åœ¨æœ€ä½ä»·æ ¼ç­‰çº§ï¼Œä¸å€¼å¾—è°ƒåº¦ï¼ˆå·²ç»æœ€ä¼˜ï¼‰
    if len(level_minutes) == 1 and price_info["min_level"] in level_minutes:
        return False

    # 4. å¦‚æœäº‹ä»¶åœ¨é«˜ä»·æ ¼åŒºé—´çš„æ—¶é—´ < é˜ˆå€¼ï¼Œä¸å€¼å¾—è°ƒåº¦
    # ï¼ˆå³ä½¿æœ‰é«˜ä»·æ ¼åŒºé—´ï¼Œä½†æ—¶é—´å¤ªçŸ­ï¼Œè°ƒåº¦æˆæœ¬å¤§äºæ”¶ç›Šï¼‰
    return False

def should_keep_for_tou_rescheduling(level_minutes, price_info, threshold_minutes=5):
    """
    TOU filtering logic: Determine if events are worth rescheduling
    Keep events that have >= 5 minutes in non-lowest price periods

    ğŸ¯ æ”¹è¿›ç‰ˆæœ¬ï¼šè€ƒè™‘ç»å¯¹ä»·æ ¼å·®å¼‚ï¼Œè€Œä¸ä»…ä»…æ˜¯ç›¸å¯¹ç­‰çº§
    """
    if not level_minutes:
        return False

    # TOU filtering logic: determine if worth rescheduling
    # 1. Calculate event duration in lowest price level (Level 0)
    low_price_minutes = level_minutes.get(price_info["min_level"], 0)
    total_minutes = sum(level_minutes.values())

    # 2. If event runs entirely in lowest price period, not worth rescheduling
    if low_price_minutes == total_minutes:
        return False

    # ğŸ¯ æ”¹è¿›ï¼šè®¡ç®—åŠ æƒä»·æ ¼å·®å¼‚ï¼Œè€Œä¸ä»…ä»…çœ‹ç­‰çº§
    lowest_price = price_info["levels"][price_info["min_level"]]

    # è®¡ç®—äº‹ä»¶åœ¨é«˜ä»·æ ¼æ—¶æ®µçš„åŠ æƒæ—¶é—´å’Œä»·æ ¼å·®å¼‚
    high_price_weighted_minutes = 0
    for level, minutes in level_minutes.items():
        if level > price_info["min_level"]:
            current_price = price_info["levels"][level]
            price_diff = current_price - lowest_price
            # ä»·æ ¼å·®å¼‚è¶Šå¤§ï¼Œæƒé‡è¶Šé«˜
            high_price_weighted_minutes += minutes * (price_diff / lowest_price)

    # 3. å¦‚æœåŠ æƒé«˜ä»·æ ¼æ—¶é—´ >= é˜ˆå€¼ï¼Œå€¼å¾—è°ƒåº¦
    # è¿™æ ·å¯ä»¥æ›´å¥½åœ°å¤„ç†å­£èŠ‚æ€§ä»·æ ¼å·®å¼‚
    if high_price_weighted_minutes >= threshold_minutes * 0.1:  # é™ä½é˜ˆå€¼ï¼Œå› ä¸ºä½¿ç”¨äº†åŠ æƒ
        return True

    # 4. å¤‡ç”¨é€»è¾‘ï¼šå¦‚æœåœ¨éæœ€ä½ä»·æ ¼ç­‰çº§çš„æ—¶é—´ >= é˜ˆå€¼ï¼Œä¹Ÿå€¼å¾—è°ƒåº¦
    non_low_price_minutes = sum(minutes for level, minutes in level_minutes.items()
                               if level > price_info["min_level"])

    if non_low_price_minutes >= threshold_minutes:
        return True

    # 5. Otherwise, rescheduling benefit too small, not worth it
    return False

def process_and_mask_events(
    event_csv_path,
    constraint_json_path,
    tariff_name="Economy_7",
    tariff_config_path=None,
    output_dir="./output/04_TOU_filter/",
    house_id="house1"
):
    # Auto-detect tariff config path if not provided
    if tariff_config_path is None:
        # For California TOU_D, use specific config file
        if tariff_name == "TOU_D":
            possible_paths = [
                "./config/TOU_D.json",
                "../config/TOU_D.json",
                "../Agent_V2/config/TOU_D.json",
                "./Agent_V2/config/TOU_D.json",
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "TOU_D.json")
            ]
        elif tariff_name in ["Germany_Variable", "Germany_Variable_Base"]:
            # For Germany tariffs, use specific config file
            possible_paths = [
                "./config/Germany_Variable.json",
                "../config/Germany_Variable.json",
                "../Agent_V2/config/Germany_Variable.json",
                "./Agent_V2/config/Germany_Variable.json",
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "Germany_Variable.json")
            ]
        else:
            # For UK tariffs, use general config file
            possible_paths = [
                "./config/tariff_config.json",
                "../config/tariff_config.json",
                "../Agent_V2/config/tariff_config.json",
                "./Agent_V2/config/tariff_config.json",
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "config", "tariff_config.json")
            ]

        for path in possible_paths:
            if os.path.exists(path):
                tariff_config_path = path
                break
        if tariff_config_path is None:
            if tariff_name == "TOU_D":
                tariff_config_path = "./config/TOU_D.json"
            elif tariff_name in ["Germany_Variable", "Germany_Variable_Base"]:
                tariff_config_path = "./config/Germany_Variable.json"
            else:
                tariff_config_path = "./config/tariff_config.json"

    # åŠ è½½äº‹ä»¶æ•°æ® - ä»æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤å™¨çš„è¾“å‡º
    df = pd.read_csv(event_csv_path, parse_dates=["start_time", "end_time"])
    df["is_reschedulable"] = df["is_reschedulable"].astype(bool)

    # TOUè¿‡æ»¤å™¨åªå¤„ç†is_reschedulable=Trueçš„äº‹ä»¶
    # æå–è¿™äº›å¯è°ƒåº¦äº‹ä»¶è¿›è¡ŒTOUåˆ†æ
    reschedulable_events = df[df["is_reschedulable"] == True].copy()

    # ç»Ÿè®¡è¾“å…¥æ•°æ®
    input_reschedulable = len(reschedulable_events)

    print(f"ğŸ“Š TOU Filter Processing:")
    print(f"  â€¢ Extracted is_reschedulable=True events from P043 output: {input_reschedulable:,}")
    print(f"  â€¢ Will perform TOU price analysis on these events")

    # Load constraint dictionary
    with open(constraint_json_path, "r", encoding="utf-8") as f:
        constraint_dict = json.load(f)

    # Load tariff configuration
    with open(tariff_config_path, "r", encoding="utf-8") as f:
        tariff_config = json.load(f)

    if tariff_name not in tariff_config:
        raise ValueError(f"âŒ Tariff configuration not found for: {tariff_name}")

    # TOU filter core logic: analyze price characteristics of reschedulable events
    # Determine if these events are worth time-shifting optimization

    print(f"ğŸ”„ Analyzing price characteristics of {input_reschedulable:,} reschedulable events...")
    print(f"ğŸ“‹ Filtering criteria:")
    print(f"  â€¢ Events running entirely in lowest price period (Level 0) â†’ not worth rescheduling")
    print(f"  â€¢ Events with <5 minutes in non-lowest price periods â†’ rescheduling benefit too small")

    # Create output DataFrame containing only reschedulable events
    output_df = reschedulable_events.copy()

    # Step 1: Price level analysis based on scheduling value
    # For seasonal tariffs like TOU_D, process events by month

    # Initialize all price-related columns
    output_df["price_level_profile"] = ""
    output_df["primary_price_level"] = -1
    output_df["start_price_level"] = -1
    output_df["end_price_level"] = -1
    output_df["optimization_potential"] = 0.0

    # Check if this is a seasonal tariff
    temp_price_info = get_price_levels(tariff_config, tariff_name)

    # Check if tariff has seasonal rates
    config_key = list(tariff_config.keys())[0] if len(tariff_config) == 1 else tariff_name
    is_seasonal = "seasonal_rates" in tariff_config[config_key]

    if temp_price_info["levels"]:  # Only filter when there are multiple price levels
        if is_seasonal:
            # For seasonal tariffs, process events by month
            print(f"ğŸŒ Processing seasonal tariff {tariff_name} by month...")

            # Group events by month
            output_df["month"] = output_df["start_time"].dt.month
            months_in_data = output_df["month"].unique()

            for month in months_in_data:
                month_events = output_df[output_df["month"] == month]
                if len(month_events) == 0:
                    continue

                print(f"ğŸ“… Processing month {month}: {len(month_events)} events")

                # Get price info for this specific month
                price_info = get_seasonal_price_levels(tariff_config, tariff_name, month)

                for idx, row in month_events.iterrows():
                    try:
                        # Mark price levels for start and end times
                        start_level = get_time_price_level(row["start_time"], price_info)
                        end_level = get_time_price_level(row["end_time"], price_info)
                        output_df.at[idx, "start_price_level"] = start_level
                        output_df.at[idx, "end_price_level"] = end_level

                        # Analyze event's price level distribution
                        level_minutes = get_event_price_profile(
                            row["start_time"], row["end_time"], price_info
                        )

                        # Update DataFrame - ensure all records have values
                        output_df.at[idx, "price_level_profile"] = json.dumps(level_minutes) if level_minutes else "{}"

                        if level_minutes:
                            primary_level = max(level_minutes.keys(), key=lambda x: level_minutes[x])
                            output_df.at[idx, "primary_price_level"] = primary_level
                            output_df.at[idx, "optimization_potential"] = primary_level / price_info["max_level"]

                            # TOU filtering logic: determine if event is worth rescheduling
                            should_reschedule = should_keep_for_tou_rescheduling(level_minutes, price_info, threshold_minutes=5)
                            if not should_reschedule:
                                output_df.at[idx, "is_reschedulable"] = False
                        else:
                            # Use default values if no price distribution found
                            output_df.at[idx, "primary_price_level"] = price_info["min_level"]
                            output_df.at[idx, "optimization_potential"] = 0.0
                            output_df.at[idx, "price_level_profile"] = "{}"

                    except Exception as e:
                        print(f"âš ï¸ Error processing event {row.get('event_id', idx)}: {e}")
                        # Use safe default values on error
                        output_df.at[idx, "price_level_profile"] = "{}"
                        output_df.at[idx, "primary_price_level"] = price_info["min_level"]
        else:
            # For non-seasonal tariffs, process all events with same price structure
            price_info = temp_price_info
            for idx, row in output_df.iterrows():
                try:
                    # Mark price levels for start and end times
                    start_level = get_time_price_level(row["start_time"], price_info)
                    end_level = get_time_price_level(row["end_time"], price_info)
                    output_df.at[idx, "start_price_level"] = start_level
                    output_df.at[idx, "end_price_level"] = end_level

                    # Analyze event's price level distribution
                    level_minutes = get_event_price_profile(
                        row["start_time"], row["end_time"], price_info
                    )

                    # Update DataFrame - ensure all records have values
                    output_df.at[idx, "price_level_profile"] = json.dumps(level_minutes) if level_minutes else "{}"

                    if level_minutes:
                        primary_level = max(level_minutes.keys(), key=lambda x: level_minutes[x])
                        output_df.at[idx, "primary_price_level"] = primary_level
                        output_df.at[idx, "optimization_potential"] = primary_level / price_info["max_level"]

                        # TOU filtering logic: determine if event is worth rescheduling
                        should_reschedule = should_keep_for_tou_rescheduling(level_minutes, price_info, threshold_minutes=5)
                        if not should_reschedule:
                            output_df.at[idx, "is_reschedulable"] = False
                    else:
                        # Use default values if no price distribution found
                        output_df.at[idx, "primary_price_level"] = price_info["min_level"]
                        output_df.at[idx, "optimization_potential"] = 0.0
                        output_df.at[idx, "price_level_profile"] = "{}"

                except Exception as e:
                    print(f"âš ï¸ Error processing event {row.get('event_id', idx)}: {e}")
                    # Use safe default values on error
                    output_df.at[idx, "price_level_profile"] = "{}"
                    output_df.at[idx, "primary_price_level"] = price_info["min_level"]
                    output_df.at[idx, "start_price_level"] = price_info["min_level"]
                    output_df.at[idx, "end_price_level"] = price_info["min_level"]
                    output_df.at[idx, "optimization_potential"] = 0.0
    else:
        # å¹³ä»·ç”µä»·æƒ…å†µ
        output_df["price_level_profile"] = "{}"
        output_df["primary_price_level"] = 0
        output_df["start_price_level"] = 0
        output_df["end_price_level"] = 0
        output_df["optimization_potential"] = 0.0

    # Add price level description when saving results
    if temp_price_info["levels"]:
        level_mapping = {i: f"Level_{i}({rate})" for i, rate in enumerate(temp_price_info["levels"])}
        print(f"ğŸ“Š Price level mapping for {tariff_name}:")
        for level, desc in level_mapping.items():
            print(f"   {desc}")

    # Save results - using new path structure
    # output_dir/{tariff_type}/{tariff_plan}/house1/tou_filtered_house1_{tariff_plan}.csv
    # Infer tariff_type from tariff_config
    tariff_type_mapping = {
        "Economy_7": "UK",
        "Economy_10": "UK",
        "Germany_Variable": "Germany",
        "TOU_D": "California"
    }
    inferred_tariff_type = tariff_type_mapping.get(tariff_name, "UK")

    # Calculate final statistics
    final_reschedulable = len(output_df[output_df["is_reschedulable"] == True])
    events_filtered_out = input_reschedulable - final_reschedulable
    filter_efficiency = (events_filtered_out / input_reschedulable * 100) if input_reschedulable > 0 else 0

    # Output statistics
    print(f"ğŸ“Š TOU filtering statistics for {tariff_name}:")
    print(f"  â€¢ Processed reschedulable events: {input_reschedulable:,}")
    print(f"  â€¢ Final reschedulable events: {final_reschedulable:,}")
    print(f"  â€¢ Events filtered out by TOU: {events_filtered_out:,}")
    print(f"  â€¢ TOU filtering efficiency: {filter_efficiency:.1f}%")
    print(f"  â€¢ Note: Filtered out events not worth rescheduling (entirely in Level 0 or <5min in non-Level 0 periods)")

    house_output_dir = os.path.join(output_dir, inferred_tariff_type, tariff_name, house_id)
    os.makedirs(house_output_dir, exist_ok=True)
    output_path = os.path.join(house_output_dir, f"tou_filtered_{house_id}_{tariff_name}.csv")
    output_df.to_csv(output_path, index=False)
    print(f"âœ… Filtered results have been saved to: {output_path}")
    return output_path


def process_single_household_complete_pipeline(
    house_id: str,
    tariff_type: str = "UK",
    tariff_plans: list = None,
    min_duration_input_dir: str = None,
    constraints_dir: str = None,
    output_dir: str = None
):
    """Process complete TOU filtering pipeline for a single household"""

    # Auto-detect paths if not provided
    if min_duration_input_dir is None:
        possible_paths = [
            "./output/04_min_duration_filter",
            "../Agent_V2/output/04_min_duration_filter",
            "./Agent_V2/output/04_min_duration_filter",
            os.path.join(os.path.dirname(os.path.dirname(__file__)), "output", "04_min_duration_filter")
        ]
        for path in possible_paths:
            if os.path.exists(path):
                min_duration_input_dir = path
                break
        if min_duration_input_dir is None:
            min_duration_input_dir = "./output/04_min_duration_filter"

    if constraints_dir is None:
        possible_paths = [
            "./output/04_user_constraints",
            "../Agent_V2/output/04_user_constraints",
            "./Agent_V2/output/04_user_constraints",
            os.path.join(os.path.dirname(os.path.dirname(__file__)), "output", "04_user_constraints")
        ]
        for path in possible_paths:
            if os.path.exists(path):
                constraints_dir = path
                break
        if constraints_dir is None:
            constraints_dir = "./output/04_user_constraints"

    if output_dir is None:
        # Create output directory relative to script location
        script_dir = os.path.dirname(os.path.dirname(__file__))
        output_dir = os.path.join(script_dir, "output", "04_TOU_filter")

    if tariff_plans is None:
        # Default tariff plans for each region
        default_plans = {
            "UK": ["Economy_7", "Economy_10"],
            "Germany": ["Germany_Variable"],
            "California": ["TOU_D"]
        }
        tariff_plans = default_plans.get(tariff_type, ["Economy_7"])

    print(f"ğŸ  Processing TOU filtering for {house_id.upper()}")
    print(f"ğŸ“Š Tariff type: {tariff_type}")
    print(f"ğŸ“‹ Tariff plans: {tariff_plans}")

    results = {}

    # è¾“å…¥æ–‡ä»¶è·¯å¾„
    event_csv_path = os.path.join(min_duration_input_dir, house_id, f"min_duration_filtered_{house_id}.csv")
    constraint_json_path = os.path.join(constraints_dir, house_id, "appliance_constraints_revise_by_llm.json")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(event_csv_path):
        print(f"âŒ Event file not found: {event_csv_path}")
        return None

    if not os.path.exists(constraint_json_path):
        print(f"âŒ Constraint file not found: {constraint_json_path}")
        return None

    # å¤„ç†æ¯ä¸ªç”µä»·æ–¹æ¡ˆ
    for tariff_name in tariff_plans:
        print(f"\nğŸ”„ Processing {tariff_name}...")

        try:
            output_path = process_and_mask_events(
                event_csv_path=event_csv_path,
                constraint_json_path=constraint_json_path,
                tariff_name=tariff_name,
                tariff_config_path=None,  # Let function auto-detect
                output_dir=output_dir,
                house_id=house_id
            )

            results[tariff_name] = {
                "output_file": output_path,
                "status": "success"
            }

            print(f"âœ… {tariff_name} completed successfully!")

        except Exception as e:
            print(f"âŒ Error processing {tariff_name}: {str(e)}")
            results[tariff_name] = {
                "output_file": None,
                "status": "failed",
                "error": str(e)
            }

    return {
        "house_id": house_id,
        "tariff_type": tariff_type,
        "results": results
    }


def process_batch_households_complete_pipeline(
    house_list: list,
    tariff_type: str = "UK",
    tariff_plans: list = None,
    min_duration_input_dir: str = None,
    constraints_dir: str = None,
    output_dir: str = None
):
    """Process complete TOU filtering pipeline for multiple households"""

    # Auto-detect paths if not provided
    if min_duration_input_dir is None:
        possible_paths = [
            "./output/04_min_duration_filter",
            "../Agent_V2/output/04_min_duration_filter",
            "./Agent_V2/output/04_min_duration_filter",
            os.path.join(os.path.dirname(os.path.dirname(__file__)), "output", "04_min_duration_filter")
        ]
        for path in possible_paths:
            if os.path.exists(path):
                min_duration_input_dir = path
                break
        if min_duration_input_dir is None:
            min_duration_input_dir = "./output/04_min_duration_filter"

    if constraints_dir is None:
        possible_paths = [
            "./output/04_user_constraints",
            "../Agent_V2/output/04_user_constraints",
            "./Agent_V2/output/04_user_constraints",
            os.path.join(os.path.dirname(os.path.dirname(__file__)), "output", "04_user_constraints")
        ]
        for path in possible_paths:
            if os.path.exists(path):
                constraints_dir = path
                break
        if constraints_dir is None:
            constraints_dir = "./output/04_user_constraints"

    if output_dir is None:
        # Create output directory relative to script location
        script_dir = os.path.dirname(os.path.dirname(__file__))
        output_dir = os.path.join(script_dir, "output", "04_TOU_filter")

    if tariff_plans is None:
        # Default tariff plans for each region
        default_plans = {
            "UK": ["Economy_7", "Economy_10"],
            "Germany": ["Germany_Variable"],
            "California": ["TOU_D"]
        }
        tariff_plans = default_plans.get(tariff_type, ["Economy_7"])

    print(f"ğŸš€ Starting batch TOU filtering...")
    print(f"ğŸ  Target households: {len(house_list)}")
    print(f"ğŸ“Š Tariff type: {tariff_type}")
    print(f"ğŸ“‹ Tariff plans: {tariff_plans}")
    print("=" * 80)

    results = {}
    failed_houses = []

    for i, house_id in enumerate(house_list, 1):
        try:
            print(f"\n[{i}/{len(house_list)}] Processing {house_id}...")

            result = process_single_household_complete_pipeline(
                house_id=house_id,
                tariff_type=tariff_type,
                tariff_plans=tariff_plans,
                min_duration_input_dir=min_duration_input_dir,
                constraints_dir=constraints_dir,
                output_dir=output_dir
            )

            if result:
                results[house_id] = result
                print(f"âœ… {house_id} completed successfully!")
            else:
                failed_houses.append(house_id)
                print(f"âŒ Failed to process {house_id}")

        except Exception as e:
            print(f"âŒ Error processing {house_id}: {str(e)}")
            failed_houses.append(house_id)
            continue

        print("-" * 80)

    # Generate batch summary
    print(f"\nğŸ‰ Batch TOU filtering completed!")
    print(f"âœ… Successfully processed: {len(results)} households")
    if failed_houses:
        print(f"âŒ Failed to process: {len(failed_houses)} households")
        for house in failed_houses:
            print(f"  - {house}")

    # Generate detailed results table
    if results:
        generate_batch_results_table(results, tariff_type)

    return results


def generate_batch_results_table(results: dict, tariff_type: str):
    """Generate summary tables for batch processing results"""
    import pandas as pd

    print(f"\nğŸ“Š Batch TOU Filtering Results Summary - {tariff_type}")
    print("=" * 100)

    # Collect data for each tariff plan
    tariff_plans = set()
    for result in results.values():
        if result and 'results' in result:
            tariff_plans.update(result['results'].keys())

    tariff_plans = sorted(list(tariff_plans))

    # Generate table for each tariff plan
    for plan_name in tariff_plans:
        print(f"\nğŸ“‹ {plan_name} Results:")
        print("-" * 80)

        table_data = []

        for house_id, result in results.items():
            if result and 'results' in result and plan_name in result['results']:
                plan_result = result['results'][plan_name]

                if plan_result['status'] == 'success':
                    # Read the output file to get statistics
                    try:
                        output_file = plan_result['output_file']
                        df = pd.read_csv(output_file)

                        total_events = len(df)
                        final_reschedulable = len(df[df['is_reschedulable'] == True])

                        # è·å–é€šè¿‡æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤çš„å¯è°ƒåº¦äº‹ä»¶æ•°é‡
                        min_duration_file = f"./output/04_min_duration_filter/{house_id}/min_duration_filtered_{house_id}.csv"
                        if os.path.exists(min_duration_file):
                            min_df = pd.read_csv(min_duration_file)
                            # TOUè¿‡æ»¤å™¨å¤„ç†çš„æ˜¯é€šè¿‡æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤çš„å¯è°ƒåº¦äº‹ä»¶
                            input_reschedulable = len(min_df[min_df['is_reschedulable'] == True])
                        else:
                            input_reschedulable = 0

                        events_filtered_out = input_reschedulable - final_reschedulable
                        filter_efficiency = (events_filtered_out / input_reschedulable * 100) if input_reschedulable > 0 else 0

                        table_data.append({
                            'House_ID': house_id,
                            'Total_Events': total_events,
                            'Input_Reschedulable': input_reschedulable,
                            'Final_Reschedulable': final_reschedulable,
                            'Events_Filtered_Out': events_filtered_out,
                            'Filter_Efficiency_%': round(filter_efficiency, 1)
                        })

                    except Exception as e:
                        print(f"âš ï¸ Error reading results for {house_id}: {e}")
                        table_data.append({
                            'House_ID': house_id,
                            'Total_Events': 'Error',
                            'Input_Reschedulable': 'Error',
                            'Final_Reschedulable': 'Error',
                            'Events_Filtered_Out': 'Error',
                            'Filter_Efficiency_%': 'Error'
                        })
                else:
                    table_data.append({
                        'House_ID': house_id,
                        'Total_Events': 'Failed',
                        'Input_Reschedulable': 'Failed',
                        'Final_Reschedulable': 'Failed',
                        'Events_Filtered_Out': 'Failed',
                        'Filter_Efficiency_%': 'Failed'
                    })

        if table_data:
            # Sort table data by House_ID numerically (house1, house2, ..., house21)
            def sort_key(item):
                house_id = item['House_ID']
                if house_id.startswith('house'):
                    try:
                        return int(house_id[5:])  # Extract number after 'house'
                    except ValueError:
                        return 999  # Put invalid house IDs at the end
                return 999

            table_data.sort(key=sort_key)

            # Create and display table
            df_table = pd.DataFrame(table_data)
            print(df_table.to_string(index=False, formatters={
                'Total_Events': lambda x: f'{x:,}' if isinstance(x, int) else str(x),
                'Input_Reschedulable': lambda x: f'{x:,}' if isinstance(x, int) else str(x),
                'Final_Reschedulable': lambda x: f'{x:,}' if isinstance(x, int) else str(x),
                'Events_Filtered_Out': lambda x: f'{x:,}' if isinstance(x, int) else str(x)
            }))

            # Calculate summary statistics for successful entries
            successful_data = [row for row in table_data if isinstance(row['Total_Events'], int)]
            if successful_data:
                total_houses = len(successful_data)
                total_events = sum(row['Total_Events'] for row in successful_data)
                total_input = sum(row['Input_Reschedulable'] for row in successful_data)
                total_final = sum(row['Final_Reschedulable'] for row in successful_data)
                total_filtered = sum(row['Events_Filtered_Out'] for row in successful_data)
                avg_efficiency = sum(row['Filter_Efficiency_%'] for row in successful_data) / total_houses

                print(f"\nğŸ“Š {plan_name} Summary:")
                print(f"  â€¢ Successfully processed: {total_houses} households")
                print(f"  â€¢ Total events: {total_events:,}")
                print(f"  â€¢ Input reschedulable events: {total_input:,}")
                print(f"  â€¢ Final reschedulable events: {total_final:,}")
                print(f"  â€¢ Events filtered out by TOU: {total_filtered:,}")
                print(f"  â€¢ Average TOU filtering efficiency: {avg_efficiency:.1f}%")
        else:
            print("No data available for this tariff plan.")

    print("=" * 100)


def get_available_houses(min_duration_dir: str = None) -> list:
    """Get available houses from min duration filter output directory"""
    available_houses = []

    # Auto-detect the correct path
    if min_duration_dir is None:
        # Try different possible paths
        possible_paths = [
            "./output/04_min_duration_filter",  # Current directory
            "../Agent_V2/output/04_min_duration_filter",  # If running from TimeSeries
            "./Agent_V2/output/04_min_duration_filter",  # If running from TimeSeries
            os.path.join(os.path.dirname(os.path.dirname(__file__)), "output", "04_min_duration_filter")  # Relative to script
        ]

        min_duration_dir = None
        for path in possible_paths:
            if os.path.exists(path):
                min_duration_dir = path
                break

        if min_duration_dir is None:
            print(f"âŒ Could not find min_duration_filter directory in any of these locations:")
            for path in possible_paths:
                print(f"  - {os.path.abspath(path)}")
            # Fallback to a default list
            return [f"house{i}" for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]]

    try:
        if os.path.exists(min_duration_dir):
            print(f"ğŸ“ Scanning for houses in: {os.path.abspath(min_duration_dir)}")
            # Get all subdirectories that start with 'house'
            for item in os.listdir(min_duration_dir):
                item_path = os.path.join(min_duration_dir, item)
                if os.path.isdir(item_path) and item.startswith('house'):
                    # Check if the required min duration filtered file exists
                    expected_file = os.path.join(item_path, f"min_duration_filtered_{item}.csv")
                    if os.path.exists(expected_file):
                        available_houses.append(item)

            available_houses.sort()  # Sort for consistent ordering
            print(f"âœ… Found {len(available_houses)} houses with min duration filtered files")

        if not available_houses:
            print(f"âš ï¸ No houses found in {min_duration_dir}")
            # Fallback to a default list if no houses found
            available_houses = [f"house{i}" for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]]

    except Exception as e:
        print(f"âŒ Error scanning for available houses: {str(e)}")
        # Fallback to a default list
        available_houses = [f"house{i}" for i in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]]

    return available_houses


def main():
    """Main function for direct execution of TOU filtering"""
    print("ğŸš€ Agent V2 - TOU Optimization Event Filter")
    print("=" * 70)

    print("Please select processing mode:")
    print("1. Single household processing (Default)")
    print("2. Batch processing")

    try:
        choice = input("Enter your choice (1-2) [Default: 1]: ").strip()
        if not choice:
            choice = "1"

        # Select tariff type
        print("\nSelect tariff type:")
        print("1. UK (Default)")
        print("2. Germany")
        print("3. California")

        tariff_choice = input("Enter your choice (1-3) [Default: 1]: ").strip()
        if not tariff_choice:
            tariff_choice = "1"

        tariff_map = {"1": "UK", "2": "Germany", "3": "California"}
        tariff_type = tariff_map.get(tariff_choice, "UK")

        # Get available houses from min duration filter output
        available_houses = get_available_houses()

        if choice == "1":
            # Single household mode
            print(f"\nğŸ“‹ Available households: {available_houses}")
            house_input = input("Enter house ID (e.g., house1) [Default: house1]: ").strip()
            if not house_input:
                house_input = "house1"

            if house_input not in available_houses:
                print(f"âŒ House {house_input} not found in configuration")
                return

            # Process single household
            result = process_single_household_complete_pipeline(house_input, tariff_type)

            if result:
                print(f"\nâœ… Processing completed successfully!")
                print(f"ğŸ“Š Results for {result['tariff_type']} tariffs:")

                for plan_name, plan_result in result['results'].items():
                    if plan_result['status'] == 'success':
                        print(f"  âœ… {plan_name}: {plan_result['output_file']}")
                    else:
                        print(f"  âŒ {plan_name}: {plan_result.get('error', 'Unknown error')}")
            else:
                print(f"âŒ Processing failed")

        elif choice == "2":
            # Batch processing mode
            print(f"\nğŸ“‹ Available households: {len(available_houses)} houses")
            print("Select batch processing mode:")
            print("1. Process first 3 households")
            print("2. Process all households")
            print("3. Custom selection")

            batch_choice = input("Enter your choice (1-3) [Default: 1]: ").strip()
            if not batch_choice:
                batch_choice = "1"

            if batch_choice == "1":
                selected_houses = available_houses[:3]
            elif batch_choice == "2":
                selected_houses = available_houses
            elif batch_choice == "3":
                print(f"Available houses: {available_houses}")
                house_input = input("Enter house IDs separated by commas: ").strip()
                selected_houses = [h.strip() for h in house_input.split(',') if h.strip() in available_houses]
                if not selected_houses:
                    print("âŒ No valid houses selected")
                    return
            else:
                print("âŒ Invalid choice")
                return

            print(f"ğŸ¯ Selected houses: {selected_houses}")

            # Process batch
            results = process_batch_households_complete_pipeline(selected_houses, tariff_type)

            if results:
                print(f"\nâœ… Batch processing completed!")
                print(f"ğŸ“Š Summary:")
                print(f"  â€¢ Total processed: {len(results)} households")
                print(f"  â€¢ Tariff type: {tariff_type}")
            else:
                print(f"âŒ Batch processing failed")

        else:
            print("âŒ Invalid choice")
            return

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Process interrupted by user")
    except Exception as e:
        print(f"\nâŒ Unexpected error: {str(e)}")


if __name__ == "__main__":
    main()
