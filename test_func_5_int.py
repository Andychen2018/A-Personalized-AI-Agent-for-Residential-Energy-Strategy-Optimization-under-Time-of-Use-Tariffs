import os
import json
import pandas as pd

# å¯¼å…¥å·¥å…·å‡½æ•°
from Agent_V2.tools.p_042_user_constraints_bak import generate_default_constraints, revise_constraints_by_llm
from tools.p_044_tou_optimization_filter import process_and_mask_events

# æ–‡ä»¶è·¯å¾„å¸¸é‡
EVENT_PATH = "./output/02_event_segments/02_appliance_event_segments_id.csv"
CONSTRAINT_PATH = "./output/04_user_constraints/appliance_constraints_revise_by_llm.json"
INTERMEDIATE_PATH = "./output/04_user_constraints/shiftable_event_filtered_by_duration.csv"

def print_event_statistics(df, stage_name):
    """æ‰“å°äº‹ä»¶ç»Ÿè®¡ä¿¡æ¯"""
    print(f"ğŸ“Š {stage_name}:")
    print(f"   æ€»äº‹ä»¶æ•°: {len(df)}")
    
    if 'is_reschedulable' in df.columns:
        reschedulable = len(df[df['is_reschedulable'] == True])
        print(f"   å¯é‡æ–°è°ƒåº¦äº‹ä»¶æ•°: {reschedulable}")
    
    # æŒ‰ç”µå™¨ç±»å‹ç»Ÿè®¡
    if 'appliance_name' in df.columns:
        shiftable_appliances = ['Washing Machine', 'Tumble Dryer', 'Dishwasher']
        for appliance in shiftable_appliances:
            count = len(df[df['appliance_name'] == appliance])
            if count > 0:
                print(f"   {appliance}: {count} ä¸ªäº‹ä»¶")

def step1_generate_default_constraints_wrapper():
    """
    æ­¥éª¤1: ç”Ÿæˆé»˜è®¤çº¦æŸ
    - åŸºäºappliance_summary.jsonä¸­çš„ç”µå™¨åˆ—è¡¨
    - ä¸ºæ‰€æœ‰ç”µå™¨ç”Ÿæˆé»˜è®¤çº¦æŸè§„åˆ™
    - ä¿å­˜åˆ°config/appliance_constraints.jsonå’Œoutput/04_user_constraints/appliance_constraints.json
    """
    print("ğŸ”§ æ­¥éª¤1: ç”Ÿæˆé»˜è®¤ç”µå™¨çº¦æŸ...")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆé»˜è®¤çº¦æŸ
    default_constraint_path = "./output/04_user_constraints/appliance_constraints.json"
    if not os.path.exists(default_constraint_path):
        print("ğŸ“‹ ç”Ÿæˆé»˜è®¤çº¦æŸæ–‡ä»¶...")
        result = generate_default_constraints()
        if result:
            print("âœ… é»˜è®¤çº¦æŸæ–‡ä»¶ç”Ÿæˆå®Œæˆ")
        else:
            print("âŒ é»˜è®¤çº¦æŸæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
            return False
    else:
        print("ğŸ“‹ é»˜è®¤çº¦æŸæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ")
    
    return True

def step2_revise_constraints_by_instruction(user_instruction: str):
    """
    æ­¥éª¤2: æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ä¿®è®¢çº¦æŸ
    - è°ƒç”¨LLMè§£æç”¨æˆ·è‡ªç„¶è¯­è¨€æŒ‡ä»¤
    - åŸºäºé»˜è®¤çº¦æŸè¿›è¡Œä¿®æ”¹
    - åªé’ˆå¯¹Shiftabilityä¸ºShiftableçš„ç”µå™¨è¿›è¡Œçº¦æŸä¿®æ”¹
    - ä¿å­˜åˆ°appliance_constraints_revise_by_llm.json
    """
    print("ğŸ§  æ­¥éª¤2: æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ä¿®è®¢çº¦æŸ...")
    print(f"ç”¨æˆ·æŒ‡ä»¤: {user_instruction}")
    
    # è°ƒç”¨LLMè§£æç”¨æˆ·æŒ‡ä»¤å¹¶ä¿®è®¢çº¦æŸ
    success = revise_constraints_by_llm(user_instruction)
    
    if success:
        print("âœ… çº¦æŸå·²æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ä¿®è®¢")
        return True
    else:
        print("âš ï¸  LLMçº¦æŸè§£æå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤çº¦æŸ")
        # å¦‚æœLLMå¤±è´¥ï¼Œå¤åˆ¶é»˜è®¤çº¦æŸä½œä¸ºfallback
        default_path = "./output/04_user_constraints/appliance_constraints.json"
        if os.path.exists(default_path):
            with open(default_path, 'r', encoding='utf-8') as f:
                default_constraints = json.load(f)
            with open(CONSTRAINT_PATH, 'w', encoding='utf-8') as f:
                json.dump(default_constraints, f, indent=2, ensure_ascii=False)
            print("âœ… å·²ä½¿ç”¨é»˜è®¤çº¦æŸä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
        return False

def step3_filter_by_min_duration():
    """
    æ­¥éª¤3: æŒ‰æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤äº‹ä»¶
    - ä»02_appliance_event_segments_id.csvä¸­æå–Shiftabilityä¸ºShiftableçš„äº‹ä»¶
    - æ‰€æœ‰Shiftableäº‹ä»¶çš„is_reschedulableåˆå§‹è®¾ä¸ºTrue
    - æ ¹æ®çº¦æŸä¸­çš„min_durationå¯¹äº‹ä»¶è¿›è¡Œè¿‡æ»¤
    - å°†å°äºæœ€å°æ—¶é—´çš„äº‹ä»¶çš„is_reschedulableæ”¹ä¸ºFalse
    - ä¿å­˜åˆ°shiftable_event_filtered_by_duration.csv
    """
    print("â±ï¸  æ­¥éª¤3: æŒ‰æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤äº‹ä»¶...")
    
    # å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼šåˆ é™¤æ—§çš„ä¸­é—´æ–‡ä»¶
    if os.path.exists(INTERMEDIATE_PATH):
        os.remove(INTERMEDIATE_PATH)
        print(f"ğŸ—‘ï¸  åˆ é™¤æ—§æ–‡ä»¶: {os.path.basename(INTERMEDIATE_PATH)}")
    
    # è¯»å–äº‹ä»¶æ•°æ®
    if not os.path.exists(EVENT_PATH):
        print(f"âŒ äº‹ä»¶æ–‡ä»¶ä¸å­˜åœ¨: {EVENT_PATH}")
        return False
    
    full_df = pd.read_csv(EVENT_PATH, parse_dates=["start_time", "end_time"])
    
    # æå–Shiftabilityä¸ºShiftableçš„äº‹ä»¶
    shiftable_df = full_df[full_df["Shiftability"] == "Shiftable"].copy()
    
    # åˆå§‹åŒ–æ‰€æœ‰Shiftableäº‹ä»¶çš„is_reschedulableä¸ºTrue
    shiftable_df["is_reschedulable"] = True
    
    print(f"ğŸ“Š æå–çš„å¯ç§»åŠ¨ç”µå™¨äº‹ä»¶:")
    print(f"   æ€»å¯ç§»åŠ¨äº‹ä»¶æ•°: {len(shiftable_df)}")
    
    # è¯»å–çº¦æŸé…ç½®
    if not os.path.exists(CONSTRAINT_PATH):
        print(f"âŒ çº¦æŸæ–‡ä»¶ä¸å­˜åœ¨: {CONSTRAINT_PATH}")
        return False
    
    with open(CONSTRAINT_PATH, "r", encoding="utf-8") as f:
        constraint_dict = json.load(f)

    # æ ¹æ®min_durationè¿‡æ»¤äº‹ä»¶
    filtered_count = 0
    for idx, row in shiftable_df.iterrows():
        appliance_name = row["appliance_name"]
        min_duration = constraint_dict.get(appliance_name, {}).get("min_duration", 0)
        
        if row["duration(min)"] <= min_duration:
            shiftable_df.at[idx, "is_reschedulable"] = False
            filtered_count += 1

    # ç¡®ä¿ç›®å½•å­˜åœ¨å¹¶ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(INTERMEDIATE_PATH), exist_ok=True)
    shiftable_df.to_csv(INTERMEDIATE_PATH, index=False)
    
    print(f"âœ… æŒç»­æ—¶é—´è¿‡æ»¤å®Œæˆ:")
    print(f"   è¿‡æ»¤æ‰çš„çŸ­æ—¶äº‹ä»¶: {filtered_count} ä¸ª")
    print(f"   å‰©ä½™å¯è°ƒåº¦äº‹ä»¶: {len(shiftable_df[shiftable_df['is_reschedulable'] == True])} ä¸ª")
    print(f"   ç»“æœä¿å­˜åˆ°: {os.path.basename(INTERMEDIATE_PATH)}")
    
    print_event_statistics(shiftable_df, "After min_duration filtering")
    return True

def step4_apply_tariff_masks(test_mode=False):
    """
    æ­¥éª¤4: åº”ç”¨ç”µä»·æ©ç 
    - åŸºäºæŒç»­æ—¶é—´è¿‡æ»¤åçš„äº‹ä»¶
    - æ ¹æ®äº‹ä»¶æ‰€åœ¨æ—¶é—´åŒºé—´çš„ç”µä»·è¿›è¡Œåˆ†æ
    - æ¯”è¾ƒæ˜¯å¦æœ‰æ›´ä½ä»·æ ¼çš„æ—¶é—´åŒºé—´å¯ä¾›è¿ç§»
    - åªé’ˆå¯¹is_reschedulableä¸ºTrueçš„äº‹ä»¶è¿›è¡Œç­›é€‰
    - æ·»åŠ ä»·æ ¼ç›¸å…³åˆ—ï¼šprice_level_profile, primary_price_level, start_price_level, end_price_level, optimization_potential
    - ç”Ÿæˆæœ€ç»ˆçš„ç”µä»·æ©ç æ–‡ä»¶
    """
    print("ğŸ’° æ­¥éª¤4: åº”ç”¨ç”µä»·æ©ç ...")
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©ç›¸åº”çš„ç”µä»·æ–¹æ¡ˆ
    if test_mode:
        # æµ‹è¯•æ¨¡å¼ï¼šå¤„ç† TOU_D å’Œ Germany_Variable
        tariff_configs = [
            ("TOU_D", "./config/TOU_D.json"),
            ("Germany_Variable", "./config/Germany_Variable.json")
        ]
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šå¤„ç† TOU_D å’Œ Germany_Variable ç”µä»·æ–¹æ¡ˆ")
    else:
        # ä¸»æµç¨‹æ¨¡å¼ï¼šåªå¤„ç† Economy_7 å’Œ Economy_10
        tariff_configs = [
            ("Economy_7", "./config/tariff_config.json"),
            ("Economy_10", "./config/tariff_config.json")
        ]
        print("ğŸ  ä¸»æµç¨‹æ¨¡å¼ï¼šå¤„ç† Economy_7 å’Œ Economy_10 ç”µä»·æ–¹æ¡ˆ")
    
    output_files = []
    
    for tariff_name, config_path in tariff_configs:
        if not os.path.exists(config_path):
            print(f"âš ï¸ Config file not found: {config_path}, skipping {tariff_name}")
            continue
            
        print(f"\nğŸ”„ Processing {tariff_name} tariff...")
        
        # ä¸ºæ–°çš„åŒºé—´ç”µä»·åˆ›å»ºä¸“é—¨çš„è¾“å‡ºç›®å½•
        if tariff_name in ["TOU_D", "Germany_Variable"]:
            output_dir = f"./output/04_user_constraints/{tariff_name}/"
        else:
            output_dir = "./output/04_user_constraints/"
        
        # å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼šåˆ é™¤æ—§çš„è¾“å‡ºæ–‡ä»¶
        expected_output_path = os.path.join(output_dir, f"shiftable_event_masked_{tariff_name}.csv")
        if os.path.exists(expected_output_path):
            os.remove(expected_output_path)
            print(f"ğŸ—‘ï¸  åˆ é™¤æ—§æ–‡ä»¶: {os.path.basename(expected_output_path)}")
            
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            # è°ƒç”¨æ ¸å¿ƒè¿‡æ»¤å‡½æ•°
            final_path = process_and_mask_events(
                event_csv_path=INTERMEDIATE_PATH,
                constraint_json_path=CONSTRAINT_PATH,
                tariff_name=tariff_name,
                tariff_config_path=config_path,
                output_dir=output_dir
            )
            
            print(f"âœ… é‡æ–°ç”Ÿæˆæ–‡ä»¶: {os.path.basename(final_path)}")
            output_files.append(final_path)
            
            # è¯»å–å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            df_tariff = pd.read_csv(final_path)
            print_event_statistics(df_tariff, f"After {tariff_name} tariff filtering")
            
            # æ˜¾ç¤ºä»·æ ¼ä¼˜åŒ–ç»Ÿè®¡
            reschedulable_events = df_tariff[df_tariff['is_reschedulable'] == True]
            if len(reschedulable_events) > 0:
                avg_optimization_potential = reschedulable_events['optimization_potential'].mean()
                print(f"   å¹³å‡ä¼˜åŒ–æ½œåŠ›: {avg_optimization_potential:.2f}")
            
        except Exception as e:
            print(f"âŒ Error processing {tariff_name}: {e}")
    
    print(f"\nâœ… ç”µä»·æ©ç åº”ç”¨å®Œæˆï¼Œç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡ä»¶")
    return output_files

def filter_events_by_constraints_and_tariff(user_instruction: str = None, test_mode: bool = False):
    """
    å¯¹å¤–ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çº¦æŸåˆ†æä¸äº‹ä»¶ç­›é€‰æµç¨‹

    å®Œæ•´æµç¨‹ï¼š
    1. åŠ è½½äº‹ä»¶æ•°æ®å’Œç”µå™¨ä¿¡æ¯
    2. ç”Ÿæˆé»˜è®¤çº¦æŸï¼ˆåŸºäºç”µå™¨åˆ—è¡¨ï¼‰
    3. è§£æç”¨æˆ·æŒ‡ä»¤å¹¶ä¿®è®¢çº¦æŸï¼ˆLLMè§£æï¼‰
    4. æŒ‰æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤äº‹ä»¶
    5. åº”ç”¨ç”µä»·æ©ç è¿›è¡Œä»·æ ¼ä¼˜åŒ–åˆ†æ

    Args:
        user_instruction: ç”¨æˆ·çº¦æŸæŒ‡ä»¤ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        test_mode: False=ä¸»æµç¨‹æ¨¡å¼(Economy_7&Economy_10), True=æµ‹è¯•æ¨¡å¼(TOU_D&Germany_Variable)

    Returns:
        dict: åŒ…å«å¤„ç†çŠ¶æ€ã€æ¨¡å¼ã€è¾“å‡ºæ–‡ä»¶ç­‰ä¿¡æ¯çš„ç»“æœå­—å…¸
    """
    print("ğŸ”„ å¼€å§‹çº¦æŸåˆ†æä¸äº‹ä»¶ç­›é€‰æµç¨‹...")
    print("="*80)

    # å¦‚æœæ²¡æœ‰æä¾›ç”¨æˆ·æŒ‡ä»¤ï¼Œä½¿ç”¨é»˜è®¤æŒ‡ä»¤
    if user_instruction is None:
        user_instruction = (
            "For Washing Machine, Tumble Dryer, and Dishwasher:\n"
            "- Replace the default forbidden operating time with 23:30 to 06:00 (next day);\n"
            "- Set latest_finish to 14:00 of the next day (i.e., 38:00);\n"
            "- Ignore all events shorter than 5 minutes.\n"
            "Keep all other appliances with default scheduling rules."
        )

    # æ‰§è¡Œå®Œæ•´æµç¨‹
    try:
        # æ­¥éª¤1: ç”Ÿæˆé»˜è®¤çº¦æŸ
        if not step1_generate_default_constraints_wrapper():
            return {"status": "failed", "error": "Failed to generate default constraints"}

        # æ­¥éª¤2: æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ä¿®è®¢çº¦æŸ
        llm_success = step2_revise_constraints_by_instruction(user_instruction)

        # æ­¥éª¤3: æŒ‰æœ€å°æŒç»­æ—¶é—´è¿‡æ»¤äº‹ä»¶
        if not step3_filter_by_min_duration():
            return {"status": "failed", "error": "Failed to filter events by duration"}

        # æ­¥éª¤4: åº”ç”¨ç”µä»·æ©ç 
        output_files = step4_apply_tariff_masks(test_mode=test_mode)

        # æ„å»ºè¿”å›ç»“æœ
        result = {
            "status": "success",
            "mode": "test_mode" if test_mode else "main_mode",
            "processed_tariffs": ["TOU_D", "Germany_Variable"] if test_mode else ["Economy_7", "Economy_10"],
            "output_files": output_files,
            "llm_parsing_success": llm_success,
            "user_instruction_applied": user_instruction is not None,
            "intermediate_files": {
                "constraints": CONSTRAINT_PATH,
                "filtered_events": INTERMEDIATE_PATH
            }
        }

        print("\nâœ… çº¦æŸåˆ†æä¸äº‹ä»¶ç­›é€‰æµç¨‹å®Œæˆï¼")

        return result

    except Exception as e:
        error_msg = f"æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return {"status": "failed", "error": error_msg}

def activate_test_mode_tariffs(user_instruction: str = None):
    """
    æ¿€æ´»æµ‹è¯•æ¨¡å¼ç”µä»·æ–¹æ¡ˆ (TOU_D & Germany_Variable)

    è¿™ä¸ªå‡½æ•°ä¸“é—¨ç”¨äºå¤„ç†æµ‹è¯•æ¨¡å¼çš„ç”µä»·æ–¹æ¡ˆï¼Œç¡®ä¿ï¼š
    1. ç»“æœæ–‡ä»¶å­˜å‚¨åœ¨æ­£ç¡®çš„å­ç›®å½•ä¸­
    2. ä¸ºåç»­çš„è´¹ç”¨è®¡ç®—æä¾›æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„
    3. ä¸ä¸»æµç¨‹æ¨¡å¼å®Œå…¨åˆ†ç¦»

    Args:
        user_instruction: ç”¨æˆ·çº¦æŸæŒ‡ä»¤

    Returns:
        dict: æµ‹è¯•æ¨¡å¼å¤„ç†ç»“æœ
    """
    print("ğŸ§ª æ¿€æ´»æµ‹è¯•æ¨¡å¼ç”µä»·æ–¹æ¡ˆ (TOU_D & Germany_Variable)")
    print("="*80)

    result = filter_events_by_constraints_and_tariff(
        user_instruction=user_instruction,
        test_mode=True
    )

    if result["status"] == "success":
        print("\nğŸ“ æµ‹è¯•æ¨¡å¼æ–‡ä»¶å­˜å‚¨ä½ç½®:")
        for file_path in result["output_files"]:
            print(f"   {file_path}")

        # éªŒè¯æ–‡ä»¶æ˜¯å¦åœ¨æ­£ç¡®çš„å­ç›®å½•ä¸­
        expected_dirs = ["TOU_D", "Germany_Variable"]
        for expected_dir in expected_dirs:
            expected_file = f"./output/04_user_constraints/{expected_dir}/shiftable_event_masked_{expected_dir}.csv"
            if os.path.exists(expected_file):
                print(f"âœ… {expected_dir} æ–‡ä»¶å·²æ­£ç¡®å­˜å‚¨")
            else:
                print(f"âš ï¸  {expected_dir} æ–‡ä»¶æœªæ‰¾åˆ°: {expected_file}")

    return result

if __name__ == "__main__":
    # æµ‹è¯•ä¸»æµç¨‹æ¨¡å¼
    print("ğŸ§ª æµ‹è¯• test_func_5_int.py ä¸»æµç¨‹æ¨¡å¼")
    result = filter_events_by_constraints_and_tariff(test_mode=False)
    print("\nğŸ“‹ ä¸»æµç¨‹æ¨¡å¼ç»“æœ:")
    print(f"   çŠ¶æ€: {result['status']}")
    print(f"   å¤„ç†çš„ç”µä»·æ–¹æ¡ˆ: {result['processed_tariffs']}")
    print(f"   è¾“å‡ºæ–‡ä»¶æ•°: {len(result['output_files'])}")

    print("\n" + "="*50)

    # æµ‹è¯•æµ‹è¯•æ¨¡å¼
    print("ğŸ§ª æµ‹è¯•æµ‹è¯•æ¨¡å¼")
    test_result = activate_test_mode_tariffs()
    print("\nğŸ“‹ æµ‹è¯•æ¨¡å¼ç»“æœ:")
    print(f"   çŠ¶æ€: {test_result['status']}")
    print(f"   å¤„ç†çš„ç”µä»·æ–¹æ¡ˆ: {test_result['processed_tariffs']}")
    print(f"   è¾“å‡ºæ–‡ä»¶æ•°: {len(test_result['output_files'])}")
